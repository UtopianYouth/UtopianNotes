# 腾讯云智三面

只能说尽力了，挂了也没法bro┭┮﹏┭┮。

## 自我介绍

正常模板。

## 问题

和二面一样，面试官一开始问知道中间件ES（Elastic Search）吗，但是我没使用过且不会。整体下来，第三轮技术面的体验非常好，面试官会主动且耐心地深入拓展MySQL和Redis中间件知识，整体问题偏向于简单业务场景一点，可惜笔试直接惯性思维了，写了很长时间没有撕出来。

**1. 场景，如果在业务测试的过程中，你发现此业务性能慢到了秒级，你会怎么去排查？**

上来直接给一个很简单的业务，属于是非常温和了，可惜没回答好，和二面第二个问题的场景题一样，本质就是分析程序性能瓶颈，直接照搬回答即可。

像这种比较宽泛的问题，我个人觉得其实可答性是非常高的，非常考验面试者对于技术的理解程度。如果对于技术的应用和业务开发逻辑理解程度高，一个问题可以扯很多，然后可以和面试官聊很久，这也是给面试官留下好印象的机会。

> 根据二面第二个问题的回答模板，其实大致可以从三个方面回答，CPU，内存和磁盘/网络IO，这三个方面本质也涉及到最重要的计算机硬件资源，二面的第二个问题给出了比较详细的回答，这里做一下宏观总结。
>
> - CPU：看用户态和内核态下CPU的使用率
>   - 用户态CPU使用率高，说明有比较耗时的业务代码，结合KV存储的HTTP协议解析等场景回答（这里是最重要的，也是出现最多的耗时情况，比如MySQL语句没写好，导致查询MySQL的业务代码执行非常耗时）；
>   - 内核态CPU使用率高，说明存在大量的系统调用或者上下文切换开销，典型的就是多线程程序频繁的线程切换。
> - 内存：分析代码是否出现了大量申请内存或者程序本身需要大量内存运行
>   - 大量申请内存而不存在内存释放：典型的C++程序内存泄漏问题；
>   - 程序本身占用内存很多，导致物理内存不足，导致频繁的缺页异常处理，一直与磁盘的SWAP区进行数据交换。
> - IO：分为磁盘IO和网络IO
>   - 磁盘IO：磁盘IO很高，说明MySQL压力比较大，考虑加缓存，如果已经有缓存了，磁盘IO还是很高，说明可能出现了缓存雪崩、击穿和穿透的问题；
>   - 网络IO：使用Wireshark这样的抓包工具分析网络性能问题。
>
> 面试的时候遇到该问题，可以先从宏观的角度回答，正常来说面试官可以基于此进行继续深入追问，比如出现了内存泄漏使用什么样的工具分析或者基于Redis、MySQL的八股等。

**2. 问题再细化一点，就是我们不使用缓存，只有MySQL遇到了查询太慢的问题，你会怎么排查？**

运气很好，在匆匆忙忙准备MySQL八股的时候，刚刚好这个问题准备到了，也是我为数不多回答地比较好的问题了。

> 像这种场景题，其实和第一个问题很像，可以先从宏观的角度入手，宏观的话就两点，一个是MySQL语句偶尔执行很慢，一个是MySQL语句一直执行很慢。
>
> 情况一：只是偶尔sql语句执行很慢
>
> - 数据库在刷新脏页，在数据库运行的内存中，存放redo log，当我们执行一条更新语句的时候，数据库会在内存中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到磁盘中去，而是把这些更新的记录写入到redo log 日记中去，文件当数据库存在大量的更新时，redo log 一下就满了，数据库会全身心来把数据同步到磁盘中去的，而这个时候，就会导致我们平时正常的SQL语句突然执行的很慢，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢；
> - 当前执行的sql语句涉及到的表或者行被加锁了，只有等其它事务执行完释放锁了，当前sql语句才能继续执行下去，可以使用`show processlist` 命令查看是否是真的等待锁。
>
> 情况二：sql语句一直执行很慢，那可能需要考虑我的sql语句书写问题了
>
> - 字段没有索引，数据库只能全表扫描；
> - 字段有索引，但是没有用上，一般是对索引字段进行了**运算或者函数操作**时，索引会失效，也只能全表扫描；
> - 查询语句查询了索引以外的字段，会导致回表查询；
> - 就算查询条件的字段有索引，数据库本身不使用索引查询，而是使用全表查询
>   - 因为系统会判断索引区分度（基数，也就是索引不同值的个数）大小，如果索引基数很小，那么数据库会选择全表扫描；
>   - 如果索引基数很大，就会走索引查询，那么问题就可能是上面三个原因了。

**3. 你刚刚提到了索引，说一下你使用索引的情况，什么场景你才会使用索引？**

这里在面试时也是泛泛而谈，只说了单列索引和复合索引的使用场景，当有一个字段频繁的被使用为查询条件时，我会考虑建立单列索引，当有多个字段频繁的作为条件查询时，会考虑建立复合索引。

> 其实面试的时候可以深入说一下使用索引是为了解决查询效率慢的问题，在InnoDB存储引擎中，单列索引和复合索引可以有效避免回表查询，索引的缺点就是需要额外的存储和写入磁盘开销。
>
> - 高频查询的WHERE条件列
>  - 等值查询：例如用户中心根据`user_id`查询，必建索引；
>   - 范围查询：如订单表按`create_time`范围查询，但需注意最左匹配原则，若查询`WHERE a>1 AND b=2`，联合索引`(b,a)`可能更优；
>   - 多列组合查询：需根据区分度、查询频率、列过滤性设计联合索引顺序，例如电商查询`(shop_id, status, create_time)`，需将高区分度的`shop_id`放前面。
> - 需要排序或分组的场景
>   - `ORDER BY / GROUP BY`：若排序字段与索引顺序一致，可避免filesort,例如报表查询按`month`分组、`amount`排序，联合索引`(month, amount)`可将性能提升10倍以上；
>   - 翻页深度优化：当`limit 10000,10`时，通过建立覆盖索引`(type, create_time, id)`，将`SELECT *`改为`SELECT id`先索引覆盖定位，再回查，可避免大量回表扫描，如果不建立复合索引，会回表10010次，建立符合所以后，可以将回表次数降低为10；
> - 区分度低，但是字段频繁被更新，且作为查询条件
>   - 如状态机字段`status`，虽然区分度低，但若业务有大量`UPDATE ... WHERE status='pending'`，仍需建立索引避免锁放大；
> 
> **拓展**
>
> 什么是锁放大？
>
> 当一个无索引的UPDATE语句执行时，MySQL需要锁住**远超实际需要**的数据行，导致锁范围不必要地扩大。
>
> ```sql
>CREATE TABLE task_queue (
>     id BIGINT PRIMARY KEY,
>    task_data JSON,
>     status VARCHAR(20),  -- 无索引
>     worker_id INT,
>     created_at TIMESTAMP
> );
> 
> -- 工作线程不断执行：
> UPDATE task_queue 
> SET status='processing', worker_id=123 
> WHERE status='pending' 
> LIMIT 1;
> ```
> 
> 无索引时的执行过程
> 
> - MySQL对`task_queue`表进行全表扫描；
>- 对扫描的每一行都尝试加锁；
> - 找到`status='pending'`的行，修改并持有锁；
>- 事务提交前，所有扫描过的行都被锁定；
> 
> 结果：表有1000万行，其中`status='pending'`的只有1000行，一次UPDATE可能扫描100万行才找到一行`pending`，100万行在事务期间都被上锁，其他工作线程被阻塞，整个任务队列卡死。
> 
> 有索引时的执行过程
>
> ```sql
># 创建索引
> CREATE INDEX idx_status ON task_queue(status);
>```
> 
> - 通过索引`idx_status`直接定位到`status='pending'`的行；
> - 只对这些行加锁（可能加锁多行是因为间隙锁，但远少于全表）；
> - 其他`status!='pending'`的行完全不受影响。
>
> 结果：扫描到`status!='pending'`的行，才进行行锁。

**4. 如何判断索引是否使用成功了，你刚刚说到了使用`EXPLAIN`命令，那么当使用`EXPLAIN`命令时，你会关注查询语句的什么字段？**

纯属给自己挖了坑，面试时只知道`EXPLAIN`命令可以分析`select`查询语句执行的详细流程，包括使用了什么索引等，但是`EXPLAIN`命令没有使用过，所以给问懵了。

> `EXPLAIN`命令执行后，会显示的字段如下，后面面试的时候，其实只要记住前面3到4个经常关注且重要的即可。
>
> **1. type字段**
>
> 该字段是访问类型字段，决定了数据访问的基本方式，按性能从优到劣排序如下。
>
> | 类型            | 含义           | 性能 | 出现场景                       |
> | --------------- | -------------- | ---- | ------------------------------ |
> | **system**      | 系统表，仅一行 | 最优 | 极少见，系统表                 |
> | **const**       | 常量查询       | 极优 | 主键/唯一索引的等值查询        |
> | **eq_ref**      | 唯一索引关联   | 极优 | JOIN，主键关联                 |
> | **ref**         | 普通索引查询   | 优   | 二级索引等值查询               |
> | **ref_or_null** | 索引查询+NULL  | 良   | `WHERE col='a' OR col IS NULL` |
> | **range**       | 范围查询       | 良   | `BETWEEN`、`IN`、`>`、`<`等    |
> | **index**       | 索引全扫描     | 中   | 覆盖索引，但需遍历全部         |
> | **ALL**         | 全表扫描       | 差   | 无索引可用                     |
>
> - 线上核心查询需达到ref 或 range 级别；
>- index级别需结合rows评估，超过1万行要考虑优化；
> - 绝对避免ALL，除非小表（<1000行），全表扫描的性能非常差。
> 
> **2. key字段**
>
> 该字段表示查询过程中，实际使用的字段。
>
> ```sql
>-- 示例输出
> EXPLAIN SELECT * FROM users WHERE age > 20;
> +----+-------------+-------+------+---------------+------+---------+------+--------+-------------+
> | id | select_type | table | type | possible_keys | key  | key_len | ref  | rows   | Extra       |
> +----+-------------+-------+------+---------------+------+---------+------+--------+-------------+
> |  1 | SIMPLE      | users | range| idx_age       | idx_age | 5      | NULL | 10000  | Using where |
> +----+-------------+-------+------+---------------+------+---------+------+--------+-------------+
> ```
> 
> - key为NULL，没有使用索引；
>
> - key与possible_keys不一致：MySQL优化器选择了非预期的索引
>
>   - 原因：没有使用非预期索引可能是统计信息不准确、索引区分度差；
>
>   - 解决方法：`ANALYZE TABLE`更新统计信息，或使用`FORCE INDEX`。
>
>     ```sql
>      -- 表有idx_a和idx_b，优化器选错了
>     EXPLAIN SELECT * FROM t WHERE a=1 AND b=2;
>      -- 可能用idx_a，但idx_b更好
>             
>     -- 强制使用索引
>     SELECT * FROM t FORCE INDEX(idx_b) WHERE a=1 AND b=2;
>     ```
>             
> **3. rows字段**
> 
> 该字段表示预估扫描行数，这是性能的直接体现。
>
> ```sql
>-- 表有1000万行
> EXPLAIN SELECT * FROM orders WHERE user_id=123;
>+----+-------------+--------+------+---------------+---------+---------+-------+------+-------+
> | type | key        | rows   |
> +------+------------+--------+
> | ref  | idx_user   | 5      |  -- 优秀：只扫描5行
> | ALL  | NULL       | 10000000 | -- 灾难：扫描1000万行
> +------+------------+--------+
> ```
> 
> - rows大于总行数10%，可能索引不高效；
> - rows是估值，实际用`SHOW STATUS LIKE 'Handler_read%'`验证；
> - 多次执行，看rows是否稳定。
>
> **4. Extra字段（额外信息）**
> 
> 该字段表示额外信息，有时隐藏着关键的SQL语句优化信息。
>
> | 值                           | 含义     | 优化建议                      |
>| ---------------------------- | -------- | ----------------------------- |
> | Using index                  | 覆盖索引 | 优秀，无需回表                |
>| Using where                  | 索引过滤 | 正常                          |
> | Using temporary              | 临时表   | 警惕，GROUP BY/ORDER BY无索引 |
> | Using filesort               | 文件排序 | 警惕，排序字段无索引          |
> | Using join buffer            | 关联缓存 | JOIN字段无索引或关联表大      |
> | Select tables optimized away | 优化聚合 | 优秀，如MIN/MAX用索引         |
> 
> **5. key_len字段**
> 
> 该字段表示索引使用长度。
>
> ```sql
>CREATE TABLE `users` (
>   `id` int(11) NOT NULL,
>  `name` varchar(20) DEFAULT NULL,
>   `age` int(11) DEFAULT NULL,
>   `city` varchar(10) DEFAULT NULL,
>   PRIMARY KEY (`id`),
>   KEY `idx_name_age_city` (`name`,`age`,`city`)
> );
> 
> -- 查询1：使用索引前1列
> EXPLAIN SELECT * FROM users WHERE name='张三';
> -- key_len: 20 * 3+1=61 (utf8mb4, 20字符, 可为NULL)
> 
> -- 查询2：使用索引前2列
> EXPLAIN SELECT * FROM users WHERE name='张三' AND age=25;
> -- key_len: 61 + 4+1=66 (int为4字节, 可为NULL)
> 
> -- 查询3：使用全部3列
> EXPLAIN SELECT * FROM users WHERE name='张三' AND age=25 AND city='北京';
> -- key_len: 66 + 10 * 3+1=97
> ```
> 
> - key_len短表示可能只用了部分索引；
> - key_len与索引定义不符表示可能没用到所有列；
> - 在联合索引中，key_len可判断最左前缀使用情况。
>
> **6. ref字段**
> 
> 该字段显示索引的哪一列被使用了。
>
> ```sql
>-- 示例1：常量引用
> EXPLAIN SELECT * FROM t WHERE a=1;
>-- ref: const
> 
> -- 示例2：关联查询
> EXPLAIN SELECT * FROM t1 JOIN t2 ON t1.id=t2.t1_id;
> -- t2的ref: db.t1.id
> 
> -- 示例3：函数或表达式
> EXPLAIN SELECT * FROM t WHERE DATE(create_time)='2023-01-01';
> -- ref: NULL (函数导致索引失效)
> ```
> 
> **7. select_type**
> 
> 该字段表示查询语句的查询类型，查询复杂度如下。
>
> | 类型             | 含义       | 关注点               |
>| ---------------- | ---------- | -------------------- |
> | **SIMPLE**       | 简单查询   | 无子查询/UNION       |
>| **PRIMARY**      | 最外层查询 | 复杂查询的主查询     |
> | **SUBQUERY**     | 子查询     | 可能性能问题         |
>| **DERIVED**      | 派生表     | FROM子句中的子查询   |
> | **UNION**        | UNION查询  | 关注UNION结果处理    |
>| **MATERIALIZED** | 物化子查询 | 5.6+，子查询结果物化 |
> 
>- 重点关注`DERIVED`（派生表）和`MATERIALIZED`，它们会创建临时表。

**5. 刚刚说到了使用缓存，那么你会在什么情况下选择加入缓存？**

面试的时候，结合分布式实时消息推送系统的Redis中存储了30天聊天信息热点数据，该热点数据需要频繁的查找，加入缓存可以很好地提高业务逻辑的QPS，这里回答的有点简单了。

> 首先，缓存是不能随便加的，加缓存是基于用空间换时间、用一致性换性能、用复杂度换速度的权衡，加了缓存之后，就需要考虑内存资源，数据一致性，业务复杂度等的问题。
>
> 一般地，在业界内，可以从以下四个维度参考是否需要加缓存，面试的时候可以挑两个说就可以了。
>
> **1. 性能需求维度**
>
> ```mermaid
> graph LR
>     A[请求] --> B{QPS>1000?}
>     B -->|是| C[强烈推荐缓存]
>     B -->|否| D{TP99>100ms?}
>     D -->|是| E[考虑缓存]
>     D -->|否| F[可能不需要]
> ```
>
> TP99：99th Percentile，响应时间的第 99 百分位数，有 1% 的请求响应时间超过了 100 毫秒。
>
> **2. 数据特征维度**
>
> | 特征             | 适合缓存             | 不适合缓存               |
> | ---------------- | -------------------- | ------------------------ |
> | **读多写少**     | ✅ 收益高             | ❌ 写多读少，缓存频繁失效 |
> | **数据热点明显** | ✅ 20%数据承担80%请求 | ❌ 数据访问均匀           |
> | **计算成本高**   | ✅ 复杂聚合、联表查询 | ❌ 简单KV查询             |
> | **时效性要求低** | ✅ 可容忍一定延迟     | ❌ 强一致性要求           |
> | **数据可丢失**   | ✅ 可重建的派生数据   | ❌ 核心业务数据           |
>
> **3. 业务场景维度**
>
> ```sql
> -- 1. 会话数据（Session）
> 用户ID → 用户信息、权限、状态
> -- 特征：频繁读取，修改较少，可丢失
> 
> -- 2. 配置数据
> 系统配置、业务规则、黑白名单
> -- 特征：读取频繁，变更时广播失效
> 
> -- 3. 热点数据
> 热门商品、热门文章、排行榜
> -- 特征：二八定律，少数数据承担大部分流量
> 
> -- 4. 中间计算结果
> 商品推荐列表、用户画像标签
> -- 特征：计算成本大，结果可复用
> 
> -- 5. 防重/限流计数
> 短信验证码次数、接口调用频率
> -- 特征：高频更新，需要原子操作
> ```
>
> **4. 架构约束维度**
>
> | 系统状态       | 缓存决策               |
> | -------------- | ---------------------- |
> | 数据库已达瓶颈 | 必须缓存               |
> | 微服务调用链长 | 本地缓存+分布式缓存    |
> | 跨国部署       | 边缘缓存（CDN）        |
> | 成本敏感       | 评估ROI，选择性缓存    |
> | 团队经验不足   | 从简单开始，逐步复杂化 |

**6. 刚刚你谈到了QPS，MySQL有一个约定俗成的QPS规定吗，在QPS底到什么情况下，才选择加入缓存？**

这里当时也是一头雾水，因为之前确实没有被问到过这种问题，没有思考过，MySQL查询的QPS多少是正常的，降低到多少会不支持高并发系统时，这些场景都没有思考过，不过当时面试官提了一嘴，如果QPS需求是以k为数量级的话，就需要考虑加缓存了。

> 其实上面的问题中，就有说到了，和面试官说的也基本一样吧，当QPS需求到了k级别时，就需要选择加入缓存了，MySQL在正常的高配置主机中，实际运行的QPS可能只有1k左右，这对于高并发系统来说，根本不够用。
>
> 场景拓展
>
> - 对于中小型电商系统，淡季可以选择不加入缓存机制，而在双11等购物高峰期，需要提前加入缓存，以防止MySQL服务器和后端系统崩溃。

**7. 如何保证缓存和数据库的一致性，采用什么方案？**

这里面试的时候回答的方案应该是没有问题的，因为当时运气比较好，刚刚好看到了数据一致性的八股。

> 在我们对缓存和数据库中的数据进行增删改时，如果要保证缓存和数据库的数据强一致性，只能让更新缓存和数据库变为原子操作，但是在高并发系统下面，显然是不行的，因为更新缓存和数据库如果变为原子操作，会导致服务器在很长一段时间内无法访问缓存，这对于高并发应用来说，显然是灾难性的问题。
>
> 高并发系统不追求“完美一致性”，只追求“最终一致性”，使用先更新数据库再删除缓存的方案。
>
> - 原理：先更新数据库再删除缓存，也称为`Cache-Aside`模式中的更新逻辑，先更新数据库，然后使缓存失效（删除），下次读请求时，会因缓存缺失而从数据库加载最新数据；
> - 不一致场景：在“更新数据库后，删除缓存前”这个极短的时间窗口内（因为更新数据库后马上就删除缓存，基于计算机代码执行的速度，该时间窗口可以忽略不记），可能有读请求将旧数据读入缓存，但因为这个窗口非常短，不一致的概率相对较低；
>
> - 优点：避免了“先删缓存”策略下，在更新数据库期间大量请求击穿到数据库的问题。

**8. 为什么先删除缓存，再更新数据库会导致缓存不一致的情况？**

这里没回答上来，有点窒息，但是面试官人很好，鼓励我说你保证缓存和数据库一致性的方法是对的，其实就是想考考我对于先删除数据库再删缓存这个方法的理解深度了，其实不难，但是面试的时候降智，看过的内容忘记了。

> 先删除缓存，再更新数据库会导致缓存和数据库中的数据长时间不一致。
>
> - 不希望的场景：在“删除缓存后，更新数据库前”，一个读请求可能将旧数据读入缓存，随后在数据库更新过程中，缓存中存储的一直是脏数据直到过期，这个不一致窗口期可能很长。

## 手撕环节

给一个有序数组，构造平衡二叉树。

没撕出来，思路直接就错了，从平衡二叉树的概念入手，每插入一次节点，就旋转节点，调整树的高度，思路不复杂，但是代码写了很久，面试官人也好，跟我说直接在有序数组中找根节点构造就行了┭┮﹏┭┮。

## 反问环节

哈哈又是礼貌性的问了一下一个很有意思的问题，面试官人真的非常好，当时面试完的时候，感觉就有过的希望了。

**1. 对于像腾讯云、阿里云这样的主流云厂商中，我主要还是购买ES服务器会比较多一点，但是没有购买过CPU相关的算力资源，想问下腾讯云这边有布局GPU这样的算例资源吗？**

感觉我这个问题问出来之后，显得我对于云产品的理解程度非常低啊┭┮﹏┭┮，细细想一下，像国内这样的主流云厂商，怎么可能会没有这种涉及前沿技术的算力资源呢，只是自己没有在腾讯云的官网好好去了解罢了。

## 总结

到了三面，所有问题都是基于简单的宏观场景题目，没有细致到问具体的八股。由于二面复盘没有做完，所以导致面试时回答非常一般，感觉有点摆烂的程度，觉得自己肯定过不了，然后没怎么准备。
