# 云智二面

总时长45min左右。

## 自我介绍

正常回答，感觉再多几次面试，应该能背下来了（but整体面试表现的非常差吧，只能说是）。

## 问题

**简单介绍一下在浏览器中输入URL到页面显示，都发生了什么？**

非常经典的一个计网问题，这里回答的非常不好，面试官说不用回答的这么细致，主要从web开发的角度回答。

这里应该从大的方向回答，理清楚思路，不要急。

> - 首先进行域名解析，拿到URL对应的服务器IP地址；
>
> - 进行TCP三次握手与服务器建立TCP连接；
>
> - 发送HTTP请求，服务器返回HTTP响应，浏览器通过内置的渲染相关技术，解析并且显示请求资源的内容。



**如果你发现自己的后端程序性能比较慢，从服务器开发的角度来看，你会怎么分析你的程序性能瓶颈出现在哪里？**

这里回答的也非常不好啊，我说从我的分布式实时消息推送系统来看，从两个角度分析，第一个是网络层，测试其在高并发下，是否能够稳定的支持TCP连接；一个是业务逻辑层，耗时的主要问题还是出现在数据库的操作中，因为存在基于磁盘的IO，分析是否使用redis这样的缓存技术，如果已经使用了redis，且这段业务逻辑还是非常耗时，分析是否出现了缓存雪崩，击穿和穿透。

> 从四个角度来回答，我觉得这里AI总结的还不错，简化版就是：全局监控 ==> 链路追踪 ==> 代码及剖析，一步一步深入。
>
> **全局监控，主要是CPU，内存和IO**
>
> **CPU**： 指标有`us`（用户态CPU）、`sy`（内核态CPU）
>
> - 高 `us`：说明应用代码本身占用了大量CPU，可能是计算密集型的业务逻辑出了问题，这时需要进入代码级剖析； 
>
> - 高 `sy`：说明系统调用频繁，这里可以结合一下KV存储的项目：说Redis是基于单线程模型的，最开始KV存储是基于线程池实现的，发现QPS不够高，线程池存在线程上下文切换。导致`sy`过高；
> - **工具**：`top`, `htop`, `vmstat`。
>
> **内存**：指标有可用内存、Swap使用率、Page Fault（缺页中断）
>
> - 内存不足：内存不足会导致Swap，急剧增加磁盘I/O，使性能骤降；
>
> - 内存充足，也要注意**内存泄露**，你的项目都使用C++开发，需要警惕，可以用 `valgrind`或 `gperftools`来检测。
>
> **I/O（磁盘/网络）**
>
> - **磁盘I/O**：`iowait`高、磁盘使用率100%，可能存在大量的MySQL读写操作，随机IO还是顺序IO，可以结合分布式实时消息推送系统的Comet层来解释；
>   - 解决方法：加缓存或者MySQL优化（使用索引机制等减少磁盘 IO 时间）；
> -  **网络I/O**：带宽打满、连接数过高、丢包重传，分布式实时消息推送系统 Comet 层需要管理大量WebSocket长连接，必须监控连接数、网络带宽；
>   - 解决方法：考虑在Comet层增加节点；
>   - 工具：可以使用 `iftop`, `nethogs`等工具。
>
> **请求链路追踪（定位慢请求）**
>
> 当全局监控发现某个资源异常后，我们需要定位到是哪些具体的请求导致了问题。
>
> - 结合项目聊，在分布式实时消息推送系统中，用户发送HTTP请求进行协议升级为Websocket连接后，以一个用户在房间内发送消息为例，请求链路是：Comet层 ==> 请求转发到Logic层 ==> 生产消息到 Kafka 层 ==> Job层消费消息 ==> Job层 通过 gRPC 远程调用Comet层WS帧发送逻辑 ==> Comet层 ==> 用户浏览器，通过链路追踪，可以清晰看到时间主要消耗在哪个环节；
> - 方法可以使用两个
>   - 使用分布式追踪系统（如SkyWalking, Jaeger）。为每个请求生成一个唯一TraceID，记录经过每个服务、每个数据库查询的耗时；
>   - 上述工具不知道，可以说在每一层输出对应业务执行时间的日志，然后统计分析。
>
> **代码及剖析**
>
> 当锁定到某个进程或函数后，需要使用相关工具
>
> - CPU Profiling
>   - 工具：`perf`（Linux神器）、`gperftools`（Google Performance Tools），可以分析哪些函数占用了最多的CPU时间；
>   - 结合项目：在我的KV存储项目中，如果发现QPS不达预期，用 `perf record`和 `perf report`查看热点是在HTTP协议解析上，还是在RBTree的查找逻辑上，或者是在锁的竞争上。
>
> - 内存 Profiling
>   - 工具：`valgrind --tool=massif`, `gperftools`。 **作用**：分析内存分配和泄露。



**基于上一个问题的深入，你说到了mysql的查询非常耗时，那你知道mysql支持的最大数据量是多少吗，你接触过的最大数据量是多少？**

这里直接懵了啊，我直接回答说应该最多支持百万级的数据量（我猜的），然后说我接触到的最大数据量是十万级（面试官又反问到是百万级的吗，这个不能靠猜吧）。

> 这里可以拓展一下，在InnoDB存储引擎中，对于一张表的最大数据量限制，可以从页编号的寻址范围和页框大小来计算，比如页编号是4字节，页框大小是16KB，这样的话，一张表，也就是一个主键索引支撑的最大数据量是64TB。
>
> 其实，MySQL中对于最大数据量的限制，没有特别的规定，这依赖于数据库服务器的硬件配置、数据库架构等的影响，从数据量来拓展回答：
>
> - 百万级以下的数据：这是MySQL的舒适区，通过良好的索引设计和规范的SQL查询语句，一般性能不会差；
>
> - 千万级到亿级别：选择分表和主从数据库服务器节点的机制；
>
> - 亿级以上数据：选择分库分表，使用雪花算法生成消息ID，保证了全局唯一和趋势递增，便于后续按时间或ID范围进行分片；
> - 更高级别的数据量级：使用搜索引擎（Elasticsearch），这个技术也是**一二三面全部提到的**，可以去了解一下。



**redis中有哪些最基本的数据类型？**

我回答了string，list，hash，set和zset五种常见的数据类型，还有就是stream，这里面试官反问到什么是stream，我说stream是支持消息队列的一种redis数据结构，支持发布订阅模式，然后说它的键值格式是基于 “时间戳 + id“ 的，id表示主题号。

> Redis高性能的关键之一，在于它为每种数据类型根据不同的使用场景和数据规模，设计了多种底层数据结构来实现。这被称为**编码（Encoding）**，可以通过`OBJECT ENCODING key`命令来查看一个键值对当前使用的底层编码。
>
> 首先需要明确一个点，基本数据类型，针对的是Redis对象，也就是value有哪些数据类型。
>
> 



**你说到了redis的string，可以说说redis里面的string和c++种的string实现有什么区别吗？**



**顺便说说list，hash，set和zset在redis中具体是怎么实现的？**



**说一说什么是红黑树吧？**

这个问题好像印象中问到了还挺多次的，我每次回答都从平衡二叉树谈起，说二叉树是一种二叉搜索树，由于平衡二叉树性质要求左右子树高度差不超过1，所以进行节点的插入和删除的时候，调整树的结构需要花费较多时间，因此衍生出了红黑树的概念，红黑树进行节点的插入和删除，调整树的时间开销较小（但是我这里没有非常详细的描述红黑树的概念，需要牢记口诀左根右，根叶黑，不红红，黑路同的意思）。



**说一说什么是跳跃表？**

这里回答的不是很好，就说是为了在链表中更加高效的查找，进行空间换时间的一种数据结构，它会在链表的基础上进行节点拓展多层，每拓展一层，节点数减半？

疑问：跳跃表是有序的吗，跳跃表的查找时间复杂度是logn吗？



**你说你对数据结构比较熟悉，那可以讲一下什么是压缩列表吗？**

g了，这里直接说不会。

> 压缩列表是Redis早期为了极致节省内存而设计的一种底层数据结构。它不是一个独立的数据类型，而是List、Hash和ZSet在小数据量时的默认底层实现。
>
> 它的核心思想是把所有数据和元信息（如长度）都紧凑地存储在一块连续的内存里，省去了维护大量指针的开销。这就像一列硬座火车，所有乘客紧挨着坐，虽然找人不方便（查找效率O(N)），但能装下更多人（节省内存）。



## 手撕环节

求两个整数集合的交集 ==> 使用set直接秒了（其实这里也很好奇，为什么会出这么简单的手撕题）。



## 反问环节

这里需要注意一下，最好每次面试都提前准备一下这个环节，好像每次问的都很不好。这里主要问了两个问题。



如何在日常开发中深入理解像reg，mcp，ai agent这样的概念？



腾讯云智和CSIG事业群有什么不一样的地方吗？







