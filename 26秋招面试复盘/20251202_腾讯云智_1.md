# 云智一面

总时长70min左右。

## 自我介绍

正常回答，感觉再多几次面试，应该能背下来了（but整体面试表现的非常差吧，只能说是）。

## 问题

**谈谈你对REG，AI Agent 和 MCP 的理解，日常在使用 AI 辅助编程的过程中，仅仅是停留在简单的对话模式上吗？**

这里在最后的反问环节，面试官提到了要全面了解AI编程相关的前沿技术，比如MCP，AI Agent，REG等。

> **REG（Retrieval-Enhanced Generation，检索增强式生成）**
>
> 核心思想是：模型不要光靠“死记硬背”的参数，而是先到外部知识库或者代码库里**检索相关内容**，再在此基础上生成答案。我用 CodeBuddy 时，其实每天都在用类似 RAG 的能力。比如我要改 `chat-room` 服务的启动流程，我会让助手先去读取项目里的代码和配置，比如 `server/application/chat-room/main.cc` 、 `chat-room.conf` ，包括里面用到的 `muduo` 、 `gRPC` 、 `Logic` 层 HTTP 调用这些上下文。它不是凭空瞎猜，而是**先把这些文件内容检索出来作为上下文**，再帮我解释“HTTP 服务怎么起的、gRPC 怎么监听、房间订阅怎么初始化”，然后基于这些真实代码给修改建议。这本质上就是 RAG：**检索项目内部知识 → 再生成答案和代码**。
>
> 
>
> **第二，AI Agent 的理解**
> Agent相比传统的问答，多了两个关键点：**目标导向**和**会自己用工具、分步执行**。
> 还是以我这个项目为例，比如我希望“在 Logic 服务里新增一个房间历史查询接口，兼顾 MySQL 和 Redis 缓存”。我不会只问一句“接口怎么写”，而是给 CodeBuddy 一个目标，然后让它自己：
>
> - 先列出 `server/application/logic` 下面的目录结构；
> - 自动去看 `logic/main.cc` 里 HTTP 路由是如何分发到 `api` / `service` 的；
> - 再打开 `service/message_service` 、 `RoomService` 等相关代码，看当前是怎么查消息、怎么用 Kafka 和存储；
> - 在理解现有设计的基础上，帮我设计新的 Handler、建议改哪些文件；
>
> 这整个过程，其实就是一个 Agent 在工作：它拿到一个业务目标之后，**自己规划步骤、自己调用“搜索/分析”等工具，结合上下文做决策**。
>
> 
>
> **第三，MCP（Model Context Protocol）的理解，以及和 CodeBuddy 的关系**
> MCP是Anthropic提出的 **Model Context Protocol，模型上下文协议**，我更愿意把它理解成一套**标准化的“模型插件协议”**：它规定了，像文件系统、数据库、HTTP 服务、命令行这类外部世界，要怎样通过一个统一的协议暴露给大模型，作为“上下文资源”和“可调用工具”。模型前面是一个客户端，后面有多个 MCP server，每个 server 都可以暴露自己的 tools、resources，模型就像调用插件一样去用。
>
> 从这个角度看，我用的 CodeBuddy 其实已经在实践类似 MCP 的理念了：在这个项目里，我可以让助手**列项目目录、读取 `main.cc` 、读取 `\*.conf` 、搜索特定接口、甚至执行编译或启动命令**。这些能力，在系统内部其实都被抽象成一组“标准工具接口”，模型通过某种协议去调用——这跟 MCP 的思想是一致的：**通过一套协议，把本地代码库、配置、运行时命令，统一接到模型的上下文世界里，让模型不仅能“看见”代码，还能“动手”操作。**只不过底层是不是严格使用 Anthropic 的 MCP 协议实现，要看平台方的技术栈；但从**架构思路**上，CodeBuddy 这种“模型 + 工具 + IDE”的形态，和 MCP 想解决的问题是高度一致的。
>
> **简单版本**
>
> **第一，RAG（检索增强生成）**
> 它的核心是“先查再答”，模型不会只靠参数里的记忆，而是先从外部知识库或代码库里检索，再基于检索结果生成回答。比如我在这个聊天室后端项目里，让 CodeBuddy 分析 `chat-room` 或 `logic` 服务的启动流程时，它会先读 `main.cc` 和对应的 `*.conf` 配置，把真实代码和配置当作上下文，再在此基础上给我修改建议，这其实就是一种 RAG 能力。
>
> **第二，AI Agent**
> Agent 相比普通聊天，更重要的是“目标导向 + 会自己用工具”。比如我提一个目标：“给 Logic 服务加一个房间历史查询接口，同时走 MySQL 和 Redis 缓存”，CodeBuddy 不只是回几行伪代码，而是会自己去列目录、打开 `logic/main.cc` 看路由怎么分发、再看 `service` 里消息和房间相关的实现，基于实际代码帮我设计接口和改动方案，我确认后它再自动改文件。这就是一个典型的 Agent：围绕目标，自己规划步骤、读写文件、执行命令。
>
> **第三，MCP（Model Context Protocol）**
> MCP 是 Anthropic 提出的“模型上下文协议”，可以理解成给大模型设计的一套标准插件协议：通过 MCP，可以把文件系统、命令行、数据库这类外部资源，统一包装成模型可调用的工具和上下文资源。从这个角度看，我现在用的 CodeBuddy 其实在实践类似的思想：它这边扮演 MCP 客户端的角色，通过一套标准接口去读写 Linux 文件、执行 bash 命令；而平台后端像 MCP 服务器一样，把这些外部资源统一封装成工具暴露出来，让模型能真正“接上”项目代码和运行环境。
>
> **总结**
>
> 这里在后面被问到使用AI工具的时候，可以和面试官说是有了解这些比较前沿的概念的，可以说自己已经把 LLM 当成一个**会用工具的协作开发同事**。在后端项目开发中，它会先通过类似 RAG 的方式读我的配置项和源代码，再以 Agent 的方式调用各种工具（读文件、搜索、执行命令），在调用读文件，搜索，执行命令的过程中，其实就是使用了MCP思路。



**介绍一下OSI七层模型，解释一下TCP和UDP的区别，以及TCP是如何保证可靠传输的？**

这里回答的比较一般吧，好像TCP的流量控制和拥塞控制忘记了，需要补充一下。

> TCP和UDP的区别，掌握一些比较关键的即可。
>
> |               | TCP                                                  | UDP                                                     |
> | ------------- | ---------------------------------------------------- | ------------------------------------------------------- |
> | 是否面向连接  | 面向连接：三次握手建立连接，四次挥手断开             | 无连接：直接发送                                        |
> | 传输可靠性    | 可靠：有确认、重传、顺序控制、校验和等               | 尽力而为：不保证到达、不保证顺序、不负责重传            |
> | 数据传输方式  | 字节流（Stream），无边界概念                         | 数据报（Datagram），有消息边界                          |
> | 是否保证有序  | 保证按发送顺序交付                                   | 不保证，可能乱序、丢失、重复                            |
> | 流量控制      | 有：基于接收窗口（rwnd）的滑动窗口流量控制           | 无，发送端按自己节奏发                                  |
> | 拥塞控制      | 有：慢启动、拥塞避免、快重传、快恢复等算法           | 无，协议层不关心网络拥塞                                |
> | 头部开销      | 较大，至少 20 字节                                   | 较小，固定 8 字节                                       |
> | 适用场景      | 要求可靠、有序的场景：HTTP/HTTPS、数据库、文件传输等 | 要求实时、对少量丢包可容忍：语音/视频通话、直播、游戏等 |
> | 连接状态维护  | 维护连接状态（发送/接收缓冲区、窗口、序号等）        | 无连接状态，协议层无状态                                |
> | 广播/多播支持 | 只支持一对一通信                                     | 支持广播、多播                                          |
>
> **TCP保证可靠传输**
>
> 可以按“从数据正确性 → 交付顺序 → 丢包处理 → 流量/拥塞”来理解。
>
> **校验和（Checksum）：保证数据未损坏**
>
> - TCP 头部有 **16 位校验和字段**，覆盖 TCP 头 + 数据 + 伪首部。
>
> 解决的问题：**比特错误 / 数据损坏**。
>
> 
>
> **序列号（Sequence Number）+ ACK 确认机制**
>
> - 每个 TCP 连接有一个 32 位序列号空间；
> - 发送方为每个字节编号，报文段的 seq 表示“本段数据的起始字节序号”；
> - 接收方用 **ACK（确认号）** 告诉发送方：“我已经按序收到从起始到 N−1 的所有字节，下一个期望是 N”。
>
> 机制特点：
>
> - **累计确认**：ACK=N 表示“之前所有字节都收到了”，可以减少 ACK 数量；
> - 接收方只对按序到达的最后一个连续字节发送 ACK。
>
> 解决的问题：**知道哪些数据到了、哪些没到**。
>
> 
>
> **超时重传（Timeout Retransmission）**
>
> - 发送方对每个未确认的报文段设置一个 **重传计时器（RTO）**；
> - 若在 RTO 内没有收到相应 ACK，则认为该报文段丢失，触发重传；
> - RTO 不是固定值，而是依据往返时延 RTT 动态估计：
>   - 典型算法是使用 **加权移动平均** + **偏差估计** 来计算 RTO，使其略大于 RTT。
>
> 解决的问题：**丢包能被发现并重传**。
>
> 
>
> **滑动窗口协议（Sliding Window）**
>
> - TCP 使用滑动窗口实现“流水线传输 + 流量控制”：
>   - 发送窗口：允许“已发送但未确认”的数据上限；
>   - 接收窗口：接收方还能接收的缓冲空间大小。
> - 发送方在窗口范围内可以连续发送多个报文段，不必每个都等 ACK；
> - 一旦收到 ACK，窗口右移，允许发送新的数据。
>
> 解决的问题：将 ARQ（自动重传请求）从“停等协议”升级为“连续 ARQ”，大幅提高吞吐量，为后面的流量控制提供基础（接收窗口控制发送方速率）。
>
> 
>
> **有序交付与乱序缓存**：网络中转发可能导致报文段乱序到达。
>
> 解决的问题：TCP 接收端会根据序列号将乱序段暂存于缓存，保证应用层**始终是连续、有序的字节流**。
>
> <font color = red>复习一下流量控制和拥塞控制</font>
>
> **TCP 流量控制（Flow Control）**
>
> 流量控制的目标：**不要把接收方冲爆**。
>
> - 接收方通过 ACK 中的窗口字段（Advertised Window，rwnd）告诉发送方：“我当前还能接收多少字节的数据”；
> - 发送方的实际有效发送窗口 = `min(rwnd, cwnd)` （cwnd 是拥塞窗口，下节讲）；
> - 当接收方缓冲快满时，会把 rwnd 调小甚至设置为 0：发送方必须减速或暂停发送。
>
> **TCP 拥塞控制（Congestion Control）**
>
> 拥塞控制的目标：**不要把网络冲爆**，保证整体网络稳定和公平。
>
> TCP 的经典拥塞控制算法由以下几个阶段/机制构成（以 Tahoe/Reno 为代表），关键变量如下：
>
> - **cwnd（Congestion Window，拥塞窗口）**：发送方根据“对网络拥塞的估计”得出的窗口大小；
> - **ssthresh（Slow Start Threshold，慢启动阈值）**：控制何时从慢启动切换到拥塞避免。
>
> 发送方实际发送窗口为： `min(rwnd, cwnd)` 。
>
> **慢启动（Slow Start）**
>
> 目标：**从小速率开始探测网络容量，快速试探可用带宽**。
>
> 连接建立或发生超时重传时：
>
> - 初始 `cwnd = 1 MSS` （一个最大报文段大小）， `ssthresh` 通常设为一个较大的值或上次的一半。每收到一个 ACK：`cwnd += 1 MSS` （即每个 RTT roughly 翻倍）。
>
> 特点：
>
> - 指数增长：1, 2, 4, 8, ... MSS；
> - 当 `cwnd >= ssthresh` 时，进入**拥塞避免**阶段。
>
> **拥塞避免（Congestion Avoidance，AIMD）**
>
> 目标：在“可能接近网络极限”的区域，**小心地线性增加发送速率**，这避免了指数爆炸，减小了引发拥塞的概率。
>
> #### 3. 丢包检测与处理：超时 / 快重传 / 快恢复
>
> 丢包通常被看作“网络发生了拥塞”，需要降低发送速率。
>
> **情况 A：超时重传（Timeout）**
>
> - 最严重的拥塞信号。
> - 处理方式（Tahoe 风格）：
>   - `ssthresh = cwnd / 2` ；
>   - `cwnd 重置为 1 MSS` ；
>   - 重新进入 **慢启动** 阶段。
>
> **情况 B：收到 3 个重复 ACK（Fast Retransmit + Fast Recovery，Reno 风格）**
>
> - 3 个相同 ACK 意味着：“有一个中间段丢了，但之后的段还在抵达”，说明链路并未完全堵死；
> - 快重传（Fast Retransmit）：不等 RTO 超时，立即重传丢失的报文段；
> - 快恢复（Fast Recovery）：认为网络只是轻度拥塞，处理方式；
>   - `ssthresh = cwnd / 2` ；
>   - `cwnd = ssthresh + 3 * MSS` （对已收到的 3 个重复 ACK 做补偿）；
>   - 每再收到一个重复 ACK： `cwnd += 1 MSS` ；
>
> Reno 的思想：**区分严重拥塞（超时）和轻微拥塞（重复 ACK）**，对应不同的“退让力度”。
>
> 
>
> **总结**
> TCP 在可靠性上，通过 **校验和、序列号、ACK、超时重传、滑动窗口和乱序重排** 来保证数据“不错、不丢、不乱”；在端到端层面通过 **流量控制（接收窗口 rwnd）** 防止把接收方冲爆；在网络层面通过 **拥塞控制（cwnd + 慢启动、拥塞避免、快重传、快恢复）** 防止把网络冲爆，这些机制组合在一起，实现了 TCP 的可靠、有序传输。
>
> 
>
> **一些计网简称回顾**
>
> RTT（Round-Trip Time，往返时间）
>
> MSL（Max Segment Lifetime，最大报文段生存时间）



**如何判断TCP报文段网络传输的稳定性，日常有抓包过吗，使用过什么抓包工具？**

忘记了自己其实使用过Wireshark这样的抓包工具，其实拓展一下，可以说自己曾经开发过基于dpdk的用户态TCP/IP协议栈，这种网络模式对比linux内核实现的TCP/IP协议栈，具有更快的通信效率，而且可操作性高，但是编程难度较大，需要自己解析和组织TCP报文段。（如果有时间，可以复盘一下之前的dpdk程序）。

> **判断TCP报文段网络传输的稳定性**
>
> ### 1. 如何判断 TCP 报文段网络传输的稳定性？
>
> 我一般会从“**抓包 + 指标**”两个维度来判断：
>
> - **RTT时长和抖动情况**
>
>   - 看三次握手的 RTT、后续数据+ACK 的往返时间是否稳定；
>
>   - 如果 RTT 波动很小、没有明显尖刺，说明网络时延比较平滑；RTT 经常突然拉高，说明链路有时拥塞或排队很严重。
>
> - **重传率和重复ACK**
>
>   - 在 Wireshark 里可以直接看到 `TCP Retransmission` 、 `Fast Retransmission` 、 `Dup ACK` ；
>
>   - 正常情况偶尔有重传可以接受；如果连续超时重传、重复 ACK 非常多，就说明链路丢包、拥塞严重，传输明显不稳定。
>
> - **接收窗口变化情况**
>
>   - 看接收窗口（ `Window Size` ）是否频繁收缩，甚至出现“零窗口（Zero Window）”情况；
>
>   - 接收端窗口频繁被打满，说明对端处理不过来，从应用视角看会表现为卡顿和吞吐掉下来。
>
> - **总体吞吐与利用率**
>
> 
>
> **抓包工具**
>
> - 在本机或开发环境中，使用Wireshark；
> - 在服务器上更多用：`tcpdump` 指令
>   - 例如： `tcpdump -i eth0 tcp port 8090 -w logic.pcap` ，然后在本地用 Wireshark 打开分析。
>
> **简单的dpdk用户态TCP/IP协议栈开发流程如下**
>
> 以「收包 → 协议处理 → 发包」为主线，可以压缩成 5 步：
>
> 1. **初始化 & 接管网卡**
>    - DPDK EAL 初始化，绑定网卡到 DPDK 驱动，配置 RX/TX 队列、内存池（mbuf pool）。
>    - 这一层把「网卡 → 内核协议栈」的路径改成「网卡 → 用户态进程」。
> 2. **轮询收包（L2/L3/L4 解析）**
>    - 用户态线程用 `rte_eth_rx_burst()` 从 RX 队列轮询收包（忙轮询，无中断）。
>    - 对每个 mbuf 解析以太网头、IP 头、TCP 头，做基本校验和过滤（目标 IP/端口等）。
> 3. **TCP/IP 状态机处理 + 用户态“socket”接口**
>    - 在用户态维护 ARP 表、路由表、TCP 连接控制块（TCB）。
>    - 实现简化版的 TCP 状态机：三次握手、四次挥手、序列号/ACK、重传、滑动窗口等。
>    - 对上提供类似 `connect()/listen()/send()/recv()` 的接口或回调，业务代码直接调用这套用户态 API。
> 4. **发送路径：构造报文 + 发到网卡**
>    - 上层调用用户态 `send()` → 协议栈组装 TCP 段、填 IP/以太网头、计算校验和。
>    - 将报文放入 mbuf，调用 `rte_eth_tx_burst()` 发送出去（零拷贝 DMA 到网卡）。
> 5. **定时器 & 重传管理**
>    - 用户态定时器周期扫描所有连接：处理超时重传、keepalive、连接超时回收等。
>    - 简单可以模仿 Reno/CUBIC 的 cwnd/ssthresh，或者根据场景自定义策略。
>
> **用户态TCP/IP协议栈对比内核态TCP/IP协议栈的区别**
>
> 感觉只要记住一些关键的就行吧
>
> | 维度            | 用户态 TCP/IP 协议栈（基于 DPDK）                            | Linux 内核 TCP/IP 协议栈                            |
> | --------------- | ------------------------------------------------------------ | --------------------------------------------------- |
> | 协议栈          | 用户态进程                                                   | 内核态                                              |
> | 数据路径        | 网卡 → DPDK 驱动 → 用户态协议栈 → 业务                       | 网卡 → 内核驱动 → 内核协议栈 → socket → 用户态      |
> | 收包方式        | **轮询（poll-mode）**，忙轮询 RX 队列，无中断                | 中断驱动为主，结合 NAPI，软中断 + 内核线程处理      |
> | 拷贝次数        | 可以做到 **零拷贝**：网卡 DMA → 用户态 mbuf                  | 通常存在 **内核 ↔ 用户态** 拷贝（recv/send 时）     |
> | 上下文切换      | 协议处理在用户态，无内核切换；少数系统调用                   | 频繁在 用户态 ↔ 内核态 切换（系统调用、协议栈处理） |
> | 延迟 & 抖动     | 延迟极低、抖动小；                                           | 延迟略高且抖动较大，但对普通业务足够，性能平衡更好  |
> | 安全性 & 稳定性 | 很大程度取决于自己实现；bug 可能导致进程崩溃或协议不兼容     | 经多年验证，稳定性、安全性、兼容性都非常成熟        |
> | 开发 & 维护成本 | 非常高：要自己维护完整协议栈、状态机、定时器、容错、安全     | 由内核社区维护，业务方只需使用 socket API           |
> | 适用场景        | 极端高性能场景：HFT、L4/L7 负载均衡器、自研网关、SDN 数据平面 | 绝大多数普通业务：Web 服务、数据库连接、微服务等    |
>
> **总结**
>
> 我会用 Wireshark / `tcpdump` 来判断 TCP 连接的稳定性，看 RTT、重传、Dup ACK、窗口变化这些指标；另外，我也尝试过基于 DPDK 写用户态 TCP/IP 协议栈，从“自己解析和组织 TCP 报文段”的角度，对 TCP 的状态机、重传和拥塞控制有比较深入的理解；对比下来，内核协议栈胜在成熟和通用，而用户态协议栈则在极端性能和业务可定制性上有明显优势，但代价是开发和运维复杂度都高很多。



**30TB的数据，如何在16GB的内存上进行排序？**

这个题没回答出来很炸裂啊，多路归并了解的太不熟悉了，要复习一下多路归并的具体流程了，但其实在面试过程中也答出来了一点。

> 以30TB数据为例子，每次可读取16GB数据到内存中排序，多路归并的思路如下：
>
> 第一步：先将30TB数据分成30TB/16GB，也就是1920份数据，将这1920份数据分别加入到内存中，进行快排，使其局部有序；
>
> 第二步：局部有序之后，进行多路归并，假设我们将16GB分成：15GB为输入缓冲区，1GB为输出缓冲区，我们可以对输入缓冲区15GB拆分成150份，每一份100MB，也就是做150路归并（每次从磁盘中拿150个文件，1920份可以拿13次），所以会生成13份文件；
>
> 第三步：基于第二步的13份文件，继续做13路归并，生成一份已排序的文件，完成归并。
>
> **这里需要深入思考归并过程**
>
> 第一步，一定要拆分成1920份，因为尽量大的局部空间有序；
>
> 第二步：其实150路归并可以自定义，也不一定是150路，可以是其它多路，150路归并的意思是，每次将1920份中的150个局部有序的文件进行排序，所以一共可以生成13份有序的大局部文件；
>
> 第三步：做13路归并即可，很好理解，因为只有13个文件了。
>
> **为什么不使用二路归并?**
>
> 如果使用二路归并，第一次1920份数据，执行一次二路归并后，生成960份，960份又进行二路归并，如此重复，会造成多次磁盘的IO，所以不合适，在IO上面非常耗时，而使用多路归并，只需要一共3次磁盘的IO。



**你知道bitmap这个数据结构吗，它的应用场景在哪里？**

拿到这个问题比较抽象啊，我当时猜的回答应用场景是磁盘的文件存储，分为顺序存储了，链式存储和索引存储，可以使用位图标识磁盘中哪些位置是已经存储数据的（为1），哪些是不存储数据的（为0），不知道对不对。



**mysql即使用了索引，为什么查询还是很慢的原因？**

这里又需要拓展了，关于查询语句的执行，mysql具体都做了些什么，内心需要非常的清楚。



**你说到了回表查询的问题，那么如何避免呢？**



**mysql事务的隔离机制有哪四种机制？**



**还问了索引的问题，在查询条件`where a=x and b=x;`中，优先使用哪一个索引？**

应该是听到了我说的最左匹配原则，面试官深入引申了一下。



这里面试官很好，关于优先使用哪一个索引，可以拓展出很多延伸的知识，面试官都进行了解释。



总结：mysql，redis，kafka这样的中间件，如果仅仅是在使用的程度上，是不行的。







