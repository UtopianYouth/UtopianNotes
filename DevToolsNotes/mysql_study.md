# MySQL入门

## 一、索引相关

这里需要拓展一下存储引擎的概念，以及MySQL服务的架构是如何实现的，如何保证高效率。

### 1.1 MySQL的索引为什么不用hash，而是使用B+树呢，hash的查找时间复杂度更低？

> **场景：我们需要select多条已经排序好的数据？**
>
> 首先，hash表中的数据只支持一次加载到内存中，而MySQL的索引是存储在磁盘中的，对于海量数据，可能导致无法将全部的索引加载到内存中，也就无法使用Hash了；
>
> 这样的话，就只能考虑使用B树和B+树了，但是B树对于批量查找有序的数据，会造成多次遍历B树，跨层访问，对于n个有序的数据，时间复杂度为：`O(n*logn)`；
>
> 所以，B树不行，使用B+树，B+树是对B树的优化，所有数据存储在叶子节点上，叶子节点通过链表链接起来了，这样对于查找批量有序的数据，我们就可以不用像B树一样，跨层多次访问了，对于n个有序的数据，时间复杂度为：`O(logn + n)`；

> **拓展：B树应用在文件索引中，那么文件索引为什么不使用二叉搜索树或者是B+树呢？**
>
> **首先为什么不使用二叉搜索树**：二叉树在内存中效率很高，但因为其“瘦高”的特性，会导致过多的磁盘I/O，完全不适合磁盘索引的场景。B树通过“矮胖”的结构，极大地减少了I/O次数，是专为磁盘等外部存储设备设计的数据结构。
>
> | 特性           | 二叉树（包括AVL树、红黑树等）                                | B树                                                          |
> | :------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
> | **树的高度**   | 高。一个节点只存一个键和两个指针，树是“瘦高”的。             | 矮。一个节点可以存放大量键和指针（比如几百个），树是“矮胖”的。 |
> | **磁盘I/O**    | 查找一个键可能需要O(log₂N)次磁盘I/O。对于十亿量级的数据，树高约30，需要几十次I/O，无法接受。 | 查找一个键通常只需要O(logₘN)次I/O（m是阶数，很大）。对于十亿量级的数据，树高通常只有3-4层，仅需3-4次I/O。 |
> | **局部性原理** | 差。每次读取一个节点（包含少量数据）可能都需要一次磁盘I/O，且节点在磁盘上不连续，无法利用预读。 | 好。B树的一个节点大小被设计为等于一个磁盘页（如4KB）。一次I/O可以读入大量键，并利用磁盘的预读特性（预读相邻数据）。 |
>
> **然后是为什么文件索引不使用B+树呢？**
>
> 在现代数据库系统中，主流的索引实现其实是B+树，而不是B树，但是文件系统（如早期的NTFS）的索引确实使用了B树，这背后的原因是查询模式的不同。
>
> - **查询以“点查询”为主**：大部分操作是根据文件名（一个具体的键）来查找文件的元数据（inode）。这种查询在B树中可能更快，因为可能在非叶子节点就命中结果；
>
> - **文件系统事务性要求较低**：B+树的叶子节点链表结构在范围查询和全顺序扫描上有巨大优势，但这在数据库（频繁做表扫描、范围查询）中更重要，对于文件系统，遍历整个目录的需求相对较少；
>
> - **实现复杂性**：在某些场景下，B树的实现可能相对B+树稍简单一些（尽管现代数据库已经证明B+树的实现非常成熟）。
>
> | 特性                  | B树                                                          | B+树                                                         |
> | :-------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
> | **数据存储位置**      | 每个节点都存放数据（键和对应的数据记录或指针）。             | 只有叶子节点存放数据，非叶子节点只起索引作用（只存放键和指向子节点的指针）。 |
> | **叶子节点链接**      | 叶子节点之间**没有**指针链接。                               | 所有叶子节点通过指针形成一个有序双向链表。                   |
> | **查找性能**          | 最好的情况是，在根节点或靠近根节点的节点就找到数据，查询很快。 | 任何查找都必须走到叶子节点，性能稳定。                       |
> | **范围查询/全盘扫描** | 效率低，需要进行中序遍历。                                   | 效率极高，找到范围下限后，沿叶子节点链表顺序扫描即可。       |

### 1.2 什么是普通索引，主键索引？

> 核心区别：普通索引叶子结点存放索引列值和主键值，主键索引叶子节点存放所有列值（针对InnoDB引擎）。
>
> | 特性     | 普通索引     | 主键索引     |
> | :------- | :----------- | :----------- |
> | 唯一性   | 不保证唯一   | 保证唯一     |
> | NULL值   | 允许         | 不允许       |
> | 数量限制 | 可创建多个   | 每表只能一个 |
> | 是否聚簇 | 否（InnoDB） | 是（InnoDB） |
> | 创建语法 | INDEX/KEY    | PRIMARY KEY  |

### 1.3 覆盖索引，回表和最左匹配原则？

> **覆盖索引**：覆盖索引是指一个索引包含了查询所需的所有字段（即select后面的所有字段都是复合索引的内容），MySQL可以直接从普通索引叶子节点中获取数据，而不需要回表查询数据行。
>
> **回表**：当索引不包含查询所需的所有字段时（即select后面的字段不全部包含在where对应的索引中），MySQL需要根据索引找到的主键值，回到主键索引（聚簇索引）中查找完整数据行的过程。
>
> **最左匹配原则**：对于复合索引（多列索引），MySQL会从左到右依次匹配索引列。查询条件必须包含索引的最左列，才能有效使用该索引。
>
> | 概念         | 核心要点                 | 优化建议                   |
> | :----------- | :----------------------- | :------------------------- |
> | **覆盖索引** | 索引包含所有查询字段     | 将SELECT字段加入索引       |
> | **回表**     | 二级索引→主键索引→数据行 | 尽量减少回表次数           |
> | **最左匹配** | 复合索引从左到右匹配     | 将高频查询条件放在索引左侧 |

### 1.4 MyISAM与InnoDB的索引，主要的差异是什么？

> **非聚簇与聚簇的区别**：一个叶子节点内容是存储数据文件的指针，一个叶子节点内容存储数据行。
>
> | 特性             | MyISAM               | InnoDB                               |
> | :--------------- | :------------------- | :----------------------------------- |
> | **索引类型**     | 全部是非聚簇索引     | 主键是聚簇索引，二级索引是非聚簇索引 |
> | **数据存储**     | 数据与索引分离存储   | 数据按主键顺序存储在聚簇索引中       |
> | **叶子节点内容** | 存储数据文件指针     | 主键索引存数据行，二级索引存主键值   |
> | **主键要求**     | 可以有非唯一主键     | 主键必须唯一，如未指定会自动生成     |
> | **回表操作**     | 所有索引都需要"回表" | 只有二级索引需要回表到聚簇索引       |
> | **索引查询效率** | 所有索引访问速度一致 | 主键索引极快，二级索引相对较慢       |



## 二、锁相关

### 2.1 什么是行锁、表锁和全局锁？

> 行锁是**粒度最细**的锁，只锁定数据表中的**单行记录**，其他事务可以并发访问表中的其他行。
>
> - 使用场景：高并发事务；
>
> 表锁是**锁定整个数据表**，同一时间只允许一个事务对表进行写操作。
>
> - 使用场景：修改表结构等DDL；
>
> 全局锁是**锁定整个MySQL实例**，使数据库处于只读状态。
>
> - 使用场景：使用`FLUSH TABLES`语句备份数据库。
>
> | 特性         | 行锁       | 表锁          | 全局锁         |
> | :----------- | :--------- | :------------ | :------------- |
> | **锁定粒度** | 单行记录   | 整张表        | 整个数据库实例 |
> | **并发性能** | 高         | 低            | 无并发         |
> | **开销成本** | 高         | 低            | 中             |
> | **适用场景** | 高并发OLTP | 批量操作、DDL | 全库备份       |
> | **默认引擎** | InnoDB     | MyISAM        | 所有引擎       |
> | **死锁风险** | 有         | 无            | 无             |
>
> 关于行锁，因为存在死锁的概念，这里顺便记录一下MySQL中是如何避免死锁的（针对MySQL，和OS的思索概念有一点不一样）。
>
> **死锁概念**：死锁是指两个或多个事务在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力干涉，这些事务都无法继续执行。
>
> **死锁的四个必要条件**
>
> - 互斥：一个资源每次只能被一个事务使用；
> - 非剥夺：已分配的资源不能被强制剥夺；
> - 占有等待：事务持有资源的同时请求新的资源 ；
> - 循环等待：事务之间形成头尾相接的循环等待链；
>
> **MySQL死锁预防**
>
> 破坏死锁的四个必要条件，具体地，MySQL可以进行如下操作（动态）：
>
> - update语句会自动加上排他锁（写锁），对于不同的事务，统一资源访问顺序，是一种有效避免死锁的方式；
> - 减小事务的粒度，将大事务拆分成多个小事务 ==> 这个操作也可以提升数据库的性能；
> - 使用乐观锁思想（先修改，对比当前记录的时间戳或者版本号，来判断其它事务是否已经修改了）；
> - 合理使用索引。
>
> 索引通过控制锁的获取顺序来预防死锁（死锁的根本原因：乱序加锁）。
>
> ```sql
> -- ❌ 无索引导致全表扫描，加锁顺序不确定
> -- 事务A（假设id=1在物理存储的前面，id=2在后面）
> UPDATE users SET status = 1 WHERE id IN (1, 2);  -- 先锁id=1，再锁id=2
> 
> -- 事务B（同时执行，但扫描顺序可能不同）  
> UPDATE users SET status = 1 WHERE id IN (2, 1);  -- 先锁id=2，再锁id=1
> 
> -- 结果：A等B释放id=2，B等A释放id=1 → 死锁！
> ```
>
> ```sql
> -- ✅ 有索引时，锁按索引顺序获取
> CREATE INDEX idx_users_id ON users(id);  -- 确保id有序
> 
> -- 事务A：按索引顺序(1→2)加锁
> UPDATE users SET status = 1 WHERE id IN (1, 2);  -- 先锁1，再锁2
> 
> -- 事务B：也按索引顺序(1→2)加锁  
> UPDATE users SET status = 1 WHERE id IN (2, 1);  -- 先锁1，再锁2
> 
> -- 结果：事务B等待事务A释放锁，不会死锁！
> ```
>
> **MySQL死锁避免**
>
> 预防死锁是在系统设计时通过制定规则来防止死锁的发生，MySQL提供了超时和死锁检测两个机制来预防死锁（静态）。
>
> ```sql
> -- 1. 超时机制
> 
> -- 1.1设置锁等待超时
> SET innodb_lock_wait_timeout = 50;  -- 默认50秒，超时自动回滚
> 
> -- 1.2 应用层重试机制
> function updateWithRetry($sql, $maxRetries = 3) {
>     for ($i = 0; $i < $maxRetries; $i++) {
>         try {
>             return executeSql($sql);
>         } catch (DeadlockException $e) {
>             if ($i === $maxRetries - 1) throw $e;
>             usleep(100000); // 等待100ms重试
>         }
>     }
> }
> 
> -- 2. 死锁检测
> 
> -- 2.1 查看死锁检测状态
> SHOW VARIABLES LIKE 'innodb_deadlock_detect';  -- 默认ON
> 
> -- 2.2 在高并发场景可关闭死锁检测（谨慎！）
> SET GLOBAL innodb_deadlock_detect = OFF;
> ```
>
> **死锁发生后解除**
>
> 这里基本就两种方式吧，一种是InnoDB有自动死锁处理机制，第二种可以手动分析和处理。
>
> ```sql
> -- 1. 自动死锁处理
> -- InnoDB自动检测死锁并回滚代价较小的事务
> -- 查看最近死锁信息
> SHOW ENGINE INNODB STATUS;
> 
> -- 输出中的"LATEST DETECTED DEADLOCK"部分显示详细信息
> 
> -- 2. 手动分析mysql的运行日志
> ```

### 2.2 InnoDB的七种锁？

#### 2.2.1 记录锁（Record Lock）

锁定单个行记录，最基本的行锁。

```sql
-- 记录锁示例
START TRANSACTION;
SELECT * FROM users WHERE id = 1 FOR UPDATE;  -- 对id=1加记录锁
-- 其他事务不能更新、删除或锁定id=1的记录
COMMIT;
```

**特点**

- 锁定索引记录（即使表没有显式索引，InnoDB也会创建隐藏聚簇索引）；
- 防止其他事务修改或锁定同一行；
- 必须有索引支持，否则会锁表。

#### 2.2.2 间隙锁（Gap Lock）

锁定索引记录之间的间隙，防止幻读。

```sql
-- 间隙锁示例：表users有id索引，现有记录id=1, 5, 10
START TRANSACTION;
SELECT * FROM users WHERE id BETWEEN 5 AND 10 FOR UPDATE;
-- 锁定间隙：(5, 10)，防止插入id=6,7,8,9的新记录
COMMIT;

-- 现有记录：1, 5, 10
-- 间隙：(-∞, 1), (1, 5), (5, 10), (10, +∞)
```

**特点**：

- 防止幻读（Phantom Read）；
- 只锁定间隙，不锁定现有记录；
- 仅在REPEATABLE-READ隔离级别有效。

#### 2.2.3 临键锁（Next-Key Lock）

记录锁和间隙锁的组合，InnoDB的默认行锁。

```sql
-- 临键锁示例
START TRANSACTION;
SELECT * FROM users WHERE id > 5 AND id < 10 FOR UPDATE;
-- 锁定：记录5和10，以及间隙(5, 10)
COMMIT;

/*
	锁定范围
	- 记录：5, 10（记录锁）
	- 间隙：(5, 10)（间隙锁）
	- 组合：临键锁锁定(5, 10]
*/
```

**特点**：

- InnoDB默认的行锁机制；
- 有效防止幻读；
- 在唯一索引上会退化为记录锁。

#### 2.2.4 意向共享锁（Intention Shared Lock, IS）

**表级锁**，表示事务打算在表中的某些行上加共享锁。

```sql
-- 意向锁是InnoDB自动管理的
SELECT * FROM users WHERE id = 1 LOCK IN SHARE MODE;
-- 自动先加IS表锁，再加S行锁
```

#### 2.2.5 意向排他锁（Intention Exclusive Lock, IX）

**表级锁**，表示事务打算在表中的某些行上加排他锁。

```sql
SELECT * FROM users WHERE id = 1 FOR UPDATE;
-- 自动先加IX表锁，再加X行锁
```

**意向锁的作用**

```sql
-- 意向锁实现表锁与行锁的兼容性检查
-- 事务A：已获得某行的X锁（自动持有IX表锁）
-- 事务B：想加表锁时，发现存在IX锁，知道有行被锁定，直接等待或拒绝
```

#### 2.2.6 自增锁（AUTO-INC Lock）

**特殊的表锁**，用于自增主键的生成。

```sql
CREATE TABLE users (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(50)
);

INSERT INTO users (name) VALUES ('Alice'), ('Bob'), ('Charlie');
-- 在自增主键分配期间持有AUTO-INC锁
```

**工作模式**：

- `innodb_autoinc_lock_mode = 0`：传统模式，语句级锁；
- `innodb_autoinc_lock_mode = 1`：连续模式（默认）；
- `innodb_autoinc_lock_mode = 2`：交错模式，最高并发。

#### 2.2.7 插入意向锁（Insert Intention Lock）

**特殊的间隙锁**，用于提高插入并发。

```sql
-- 会话A
START TRANSACTION;
SELECT * FROM users WHERE id > 5 AND id < 10 FOR UPDATE;  -- 加间隙锁(5,10)

-- 会话B：插入意向锁允许在间隙中不同位置并发插入
INSERT INTO users (id, name) VALUES (6, 'David');  -- 获取插入意向锁
INSERT INTO users (id, name) VALUES (8, 'Eve');    -- 另一个插入意向锁
```

**特点**：

- 提高插入并发性能；
- 多个插入可以在同一间隙的不同位置并发执行；
- 不会阻塞其他插入意向锁。

### 2.3 一条SQL执行很慢的原因有哪些？

> 这里分两种情况回答，比较有思路一点
>
> 情况一：只是偶尔sql语句执行很慢
>
> - 数据库在刷新脏页，在数据库运行的内存中，存放了redo log，当我们执行一条更新语句的时候，数据库会在**内存**中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到**磁盘**中去，而是把这些更新的记录写入到 redo log 日记中去，文件当数据库存在大量的更新时，redo log一下就满了，数据库会全身心来把数据同步到磁盘中去的，而这个时候，就会导致我们平时正常的SQL语句突然执行的很慢，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢；
> - 当前执行的sql语句涉及到的表或者行被加锁了，只有等其它事务执行完释放锁了，当前sql语句才能继续执行下去，可以使用`show processlist` 命令查看是否是真的等待锁。
>
> 情况二：sql语句一直执行很慢，那可能需要考虑我的sql语句书写问题了
>
> - 字段没有索引，数据库只能全表扫描；
> - 字段有索引，但是没有用上，一般是对索引字段进行了**运算或者函数操作**时，索引会失效，也只能全表扫描；
> - 查询语句查询了索引以外的字段，会导致回表查询；
> - 就算查询条件的字段有索引，数据库本身不使用索引查询，而是使用全表查询
>   - 因为系统会判断索引区分度（基数，也就是索引不同值的个数）大小，如果索引基数很小，那么数据库会选择全表扫描；
>   - 如果索引基数很大，就会走索引查询，那么问题就可能是上面三个原因了。



### 2.4 为什么我改一行的语句，锁会这么多？

这里先后续再了解。



### 2.5 幻读是什么，幻读有什么问题？

> - 脏读：读到了别人没提交的修改；
>
> - 不可重复读：同一事务中，多次读同一行，结果不一样；
>
> - 幻读：同一事务中，多次同条件范围查询，行的数量或集合变了。



## 三、日志与事务

### 3.1 MySQL中，事务的特性和四种隔离级别？

> 知道事务的ACID特性如下。
>
> - Atomicity：原子性，事务不可分割；
> - Consistency：一致性，数据状态一致；
> - Isolation：隔离性，事务间相互隔离；
> - Durability：持久性，提交后永久保存。
>
> 四种隔离级别如下。
>
> - `READ UNCOMMITTED` ：读未提交
>   - 特点：一个事务可以看到其他事务未提交的数据；
>
>   - 问题：会出现 脏读、不可重复读、幻读，基本不建议使用。
> - `READ COMMITTED` ：读已提交
>   - 特点：只允许读到已经提交的数据，不会读到未提交的中间状态；
>
>   - 解决：避免脏读；
>
>   - 问题：不可重复读、幻读；
>   - 一些数据库（如 Oracle）的默认级别就是它。
> - `REPEATABLE READ`：可重复读，InnoDB 默认隔离级别
>   - 特点：一个事务内，多次读取同一行，看到的数据是一致的快照（同一版本）；
>
>   - 解决：避免脏读 & 不可重复读；
>
>   - InnoDB 通过 MVCC & 间隙锁，在大多数场景下也能避免幻读（跟标准略有差异，面试时可以顺带提）。
>
> - `SERIALIZABLE`：可串行化
>   - 特点：最高隔离级别，理论上相当于所有事务加锁串行执行；
>
>   - 解决：脏读 & 不可重复读 & 幻读全部避免；
>
>   - 代价：并发度极低，锁冲突严重，很少在高并发业务场景使用。
>
> **什么是mysql的MVCC（多版本并发控制）？**
>
> 一句话解释MVCC就是，给每一行保留多个版本 & 生成事务自己的快照视图，让大多数读操作不用加锁，就能读到一致的数据。
>
> - MVCC 解决什么问题？==> 没有 MVCC 时，要想实现可重复读，最直接的办法是：读的时候给行加读锁，别人不能改；写的时候给行加写锁，别人不能读；
>
> - **问题**：并发度极差，大家互相锁来锁去，吞吐量很低；
>
> - **MVCC 的目标**：让读和写尽量互不阻塞，写，照常更新当前版本；读，读自己那个时间点看到的旧版本（快照），而不是强行锁住最新那一份。
>
> **InnoDB怎么实现多版本的？**
>
> - InnoDB 每一行都有两个隐藏字段（简化版理解）
>   - `trx_id` ：最后一次修改这个行的事务 ID；
>
>   - `roll_pointer` ：指向undo log的指针，通过它能找到这个行旧版本的信息。
> - 当我们对一行做 `UPDATE`操作时
>   - InnoDB 先在undo log里记录旧值；
>
>   - 然后把数据页里这一行更新为新值，把 `trx_id` 改成当前事务 ID，把 `roll_pointer` 指向刚写入的undo记录；
>
>   - 数据页里的当前行是新版本；
>   - undo链表里串着历史旧版本。
>
> InnoDB多版本存在于：当前页 & undo log的链中。
>
> **快照读是怎么挑版本的？**
>
> 当一个事务开始做快照读（普通 `SELECT` ，不带 `FOR UPDATE` ）时，InnoDB会为这个事务生成Read  View，主要包含：
>
> - 当前系统里活跃未提交事务的ID列表；
> - 当前系统分配过的最大事务ID等。
>
> 每次读某一行时，InnoDB 会沿着当前版本和undo log链往回走，找到对这个事务来说可的那个版本：
>
> - 对于REPEATABLE READ（可重复读，InnoDB 默认）
>   - 一个事务在执行过程中，多次 SELECT 用的是同一个 Read View；
>   - 可重复读看到的是事务开始那一刻的快照，即使别的事务已经提交了新的修改，它也看不到，从而避免了不可重复读。
> - 对于READ COMMITTED
>   - 每次SELECT都会生成新的Read View；
>   - 所以可以看到别人已经提交的新版本，但不会看到未提交的，解决了脏读，但允许不可重复读。
>
> 这就是同一条物理数据，不同事务、不同隔离级别下，看到不同版本的本质。
>
> **MVCC和锁的关系**
>
> - 快照读，`SELECT`：基于快照读，利用MVCC的Read View和undo机制，不加行锁也能读到一致性视图；读写之间的冲突大大减少，并发性能提升；
> - 当前读，`SELECT...FOR UPDATE`：操作当前最新版本的数据，会加行锁、间隙锁等，MVCC 主要是优化读的体验，写该加的锁还是要加。
>
> InnoDB的MVCC本质上是多版本和快照读的一套机制，每一行通过隐藏的事务ID和undo指针串起多个历史版本；当事务做普通 `SELECT` 时，InnoDB根据当前事务的Read View，在这些版本里挑一个对它可见的版本返回，这样就能在不用加锁的情况下实现可重复读，同时也让读写尽可能不互相阻塞，提高整体并发性能。





一条SQL更新语句是如何执行的？