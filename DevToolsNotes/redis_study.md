# Redis 入门

Redis 是开发高性能后端服务器的必备中间件。

## 安装

可以通过源码安装和apt安装，两种安装方式其redis相关的文件位置有区别。

**Redis 重要文件位置总结**

| 文件类型       | 包管理器安装位置                           | 源码编译安装位置                  |
| :------------- | :----------------------------------------- | :-------------------------------- |
| **主配置文件** | `/etc/redis/redis.conf`                    | `/etc/redis/redis.conf`或源码目录 |
| **服务器程序** | `/usr/bin/redis-server`                    | `/usr/local/bin/redis-server`     |
| **客户端程序** | `/usr/bin/redis-cli`                       | `/usr/local/bin/redis-cli`        |
| **数据文件**   | `/var/lib/redis/`                          | 配置文件中 `dir`指定              |
| **日志文件**   | `/var/log/redis/redis-server.log`          | 配置文件中 `logfile`指定          |
| **服务文件**   | `/lib/systemd/system/redis-server.service` | 需要手动创建                      |

## 一、Redis 介绍

> - Redis是 Key-Value 型 NoSQL 数据库；
>
> - Redis将数据存储在内存中，同时也能持久化到磁盘；
>
> - Redis常用于缓存，利用内存的高效提高程序的处理速度。
>
> **Redis 特点**
>
> - 速度快、持久化、主从复制；
> - 广泛的语言支持（常见的后端语言）；
> - 支持多种数据结构（String, List, Hash, Set, ZSet）；
> - 支持分布式和高可用。

### 1.1 Linux安装Redis

本部分参考 AI 即可，非常方便，以 Ubuntu20.04 为例：

```bash
# 1. 先安装相关依赖
sudo apt update
sudo apt install -y build-essential tcl

# 2. 在指定目录（也就是安装目录）下载Redis指定版本源码并且解压缩
wget https://download.redis.io/releases/redis-6.0.16.tar.gz
tar xzf redis-6.0.16.tar.gz
cd redis-6.0.16

# 3. 进入到安装目录后，编译且安装
make
sudo make install
```

## 二、Redis常用基本配置

安装了 redis 之后，其配置文件在安装目录下，文件名`redis.conf`即为配置文件，启动 redis 时，使用命令 `[安装目录]/src/redis-server [安装目录]/redis.conf`即可让配置文件生效。

> 配置文件一些关键项解析：
>
> | 配置项      | 示例              | 说明                    |
> | ----------- | ----------------- | ----------------------- |
> | daemonize   | daemonize yes     | 是否启用后台运行,默认no |
> | port        | port 6379         | 设置端口号,默认6379     |
> | logfile     | logfile 日志文件  | 设置日志文件            |
> | databases   | databases 255     | 设置redis数据库总量     |
> | dir         | dir 数据文件目录  | 设置数据文件存储目录    |
> | requirepass | requirepass 12345 | 设置使用密码            |

## 三、Redis常用命令

Redis 常用命令总结如下：

| 命令     | 示例              | 说明                                 |
| -------- | ----------------- | ------------------------------------ |
| `select` | `select 0`        | 选择0号数据库                        |
| `set`    | `set name lily`   | 设置 key=name, value=lily            |
| `get`    | `get hello`       | 获得 key=hello 结果                  |
| `keys`   | `keys he*`        | 根据 Pattern 表达式查询符合条件的Key |
| `dbsize` | `dbsize`          | 返回 key 的总数                      |
| `exists` | `exists a`        | 检查 key=a 是否存在                  |
| `del`    | `del a`           | 删除 key=a 的数据                    |
| `expire` | `expire hello 20` | 设置 key=hello 20秒后过期            |
| `ttl`    | `ttl hello`       | 查看 key=a 的过期剩余时间            |

## 四、Redis数据类型

在 Redis 中，不同的数据类型对应的命令不同。

### 4.1 String 类型



### 4.2 Hash 类型



### 4.3 List 类型



### 4.4 Set 类型



### 4.5 Zset 类型



## 五、高频八股

### 5.1 redis单线程为什么还能这么快？

> - 非阻塞I/O多路复用模型；
> - 纯内存操作；
> - 单线程模式，避免了不必要的上下文切换及竞争条件。

### 5.2 redis的value都有哪些数据类型，都分别有什么使用场景？

Redis不仅仅是一个简单的键值存储，它更是一个**数据结构服务器**。这是面试中非常重要的一个概念。它的value支持多种丰富的数据结构，这使得Redis能解决各种各样的问题，而不仅仅是做缓存。

| 数据类型        | 中文名   | 特点                                   | 最常用场景举例                   |
| :-------------- | :------- | :------------------------------------- | :------------------------------- |
| **String**      | 字符串   | 最基本类型，可存文本、数字、二进制数据 | 缓存、计数器、分布式锁           |
| **List**        | 列表     | 有序、可重复、支持双向操作             | 消息队列、最新列表、朋友圈时间线 |
| **Hash**        | 哈希     | 键值对集合，适合存储对象               | 存储用户信息、商品信息等对象     |
| **Set**         | 集合     | 无序、唯一、支持交并差集               | 标签、共同好友、抽奖去重         |
| **ZSet**        | 有序集合 | 唯一、有序（按分数排序）               | 排行榜、带权重的消息队列         |
| **BitMap**      | 位图     | 在String基础上进行位操作               | 用户签到、活跃度统计             |
| **HyperLogLog** | 基数统计 | 用于唯一计数，占用空间极小             | 大规模UV统计                     |
| **Geo**         | 地理空间 | 存储地理位置信息                       | 附近的人、摇一摇                 |
| **Stream**      | 流       | 用于消息队列，支持消费者组             | 类似Kafka的消息队列              |

前5种是**最核心、最常用**的数据类型，必须熟练掌握。

**String（字符串）**

这是最基础的类型，但功能非常强大。一个key对应一个value。value可以是字符串、整数或者浮点数。

**核心命令：**

```bash
# 1. 设置值（如果key已存在，则覆盖）
SET user:1:name "张三"

# 2. 获取值
GET user:1:name
# 详解：如果key不存在，返回(nil)

# 3. 设置值并设置过期时间（秒），常用于缓存
SETEX cache:key 60 "some_data"
# 详解：这是一个原子操作，等价于 SET + EXPIRE

# 4. 当key不存在时才设置值（常用于分布式锁）
SETNX lock:order_123 true
# 详解：如果lock:order_123不存在，则设置成功，返回1；如果已存在，则设置失败，返回0。

# 5. 对数字类型的value进行递增
INCR article:100:read_count
# 详解：将存储的数字值加1。如果key不存在，那么值会先被初始化为0，然后再执行INCR操作。

# 6. 对数字进行指定步长的递增/递减
INCRBY user:1:points 10
DECRBY user:1:points 5
```

- **分布式锁**：如何使用`SET key value NX PX 30000`（NX表示SETNX，PX表示毫秒级过期时间）实现一个简单的分布式锁。
- **计数器**：`INCR`命令是原子性的，非常适合做文章阅读量、点赞数等计数功能。

**List（列表）**

一个链表，按照插入顺序排序，元素可以重复。你可以从列表的头部（左边）或尾部（右边）进行操作。

**核心命令：**

```
# 1. 从列表左侧插入一个或多个值
LPUSH news:list "新闻A" "新闻B"
# 详解：执行后列表为 ["新闻B", "新闻A"]

# 2. 从列表右侧插入一个或多个值
RPUSH news:list "新闻C"
# 详解：执行后列表为 ["新闻B", "新闻A", "新闻C"]

# 3. 从列表左侧弹出一个值
LPOP news:list
# 详解：返回并移除"新闻B"，列表变为 ["新闻A", "新闻C"]

# 4. 从列表右侧弹出一个值
RPOP news:list
# 详解：返回并移除"新闻C"，列表变为 ["新闻A"]

# 5. 获取列表指定范围内的元素
LRANGE news:list 0 -1
# 详解：0表示起始索引，-1表示最后一个元素。这条命令会返回列表所有元素。

# 6. 限制列表长度（常用于定长列表，如最新10条消息）
LTRIM news:list 0 9
# 详解：只保留列表前10个元素，其余全部删除。
```

- **常用数据结构**：`LPUSH + RPOP`或 `RPUSH + LPOP`可以构成**栈**（后进先出）；`LPUSH + LPOP`或 `RPUSH + RPOP`可以构成**队列**（先进先出）。
- **应用场景**：**消息队列**（虽然现在有更专业的Stream）、**最新文章列表**（`LPUSH`新文章，然后用`LTRIM`保持固定长度）。

**Hash（哈希）**

类似于Java中的`Map`或Python中的`dict`，是一个键值对集合，非常适合存储对象。

**核心命令：**

```bash
# 1. 设置哈希表中一个字段的值
HSET user:1 name "李四" age 30 city "北京"
# 详解：一次性设置多个field-value。早期版本需要逐个设置，新版本支持批量。

# 2. 获取哈希表中一个字段的值
HGET user:1 name
# 返回："李四"

# 3. 获取哈希表中所有字段和值
HGETALL user:1
# 返回：1) "name" 2) "李四" 3) "age" 4) "30" 5) "city" 6) "北京"

# 4. 对哈希表中某个字段的值进行递增（适用于数字）
HINCRBY user:1 age 1
# 详解：将user:1的age字段增加1。

# 5. 删除哈希表中的一个或多个字段
HDEL user:1 city
```

- 对比 String：存储用户信息时，是使用一个Hash好，还是用多个String（例如`user:1:name`, `user:1:age`）好？**Hash优点**：省内存（Redis优化了存储），操作方便（`HGETALL`一次获取所有信息）。**多个String优点**：可以单独设置每个字段的过期时间，灵活性更高。
- **应用场景**：**存储对象信息**，如用户信息、商品信息、配置信息等。

**Set（集合）**

无序的、元素唯一的集合。支持集合间的操作，如交集、并集、差集。

**核心命令：**

```bash
# 1. 向集合添加一个或多个成员
SADD tags:article:100 "java" "redis" "database"

# 2. 返回集合中的所有成员
SMEMBERS tags:article:100

# 3. 判断成员是否是集合的成员
SISMEMBER tags:article:100 "java"
# 返回：1（存在）或0（不存在）

# 4. 获取集合的成员数
SCARD tags:article:100

# 5. 计算多个集合的交集/并集/差集
SADD tags:user:1 "java" "python"
SADD tags:user:2 "java" "go"

# 计算user1和user2的共同标签（交集）
SINTER tags:user:1 tags:user:2
# 返回："java"

# 计算user1和user2所有的标签（并集）
SUNION tags:user:1 tags:user:2

# 计算user1有但user2没有的标签（差集）
SDIFF tags:user:1 tags:user:2
```

- **应用场景**
- **标签系统**：给文章/用户打标签；
- **共同好友/关注**：`SINTER`命令非常高效；
- **抽奖活动**：利用唯一性，确保用户不重复中奖。

**ZSet / Sorted Set（有序集合）**

和Set一样，也是元素唯一的集合。但每个元素都会关联一个`score`（分数），Redis通过分数来为集合中的成员进行从小到大的排序。

```bash
# 1. 向有序集合添加一个或多个成员，或更新已存在成员的分数
ZADD leaderboard 100 "user1" 200 "user2" 50 "user3"
# 详解：100, 200, 50 就是score。

# 2. 按分数从低到高返回指定区间的成员（0到-1表示返回所有）
ZRANGE leaderboard 0 -1
# 返回：1) "user3" 2) "user1" 3) "user2"

# 3. 按分数从高到低返回指定区间的成员（常用于排行榜）
ZREVRANGE leaderboard 0 2 WITHSCORES
# 返回：1) "user2" 2) "200" 3) "user1" 4) "100" 5) "user3" 6) "50"
# 详解：WITHSCORES选项会同时返回分数。

# 4. 获取指定成员的排名（排名从0开始）
ZRANK leaderboard "user1"   # 升序排名，返回1
ZREVRANK leaderboard "user1" # 降序排名，返回1（在ZREVRANGE中的排名）

# 5. 获取指定成员的分数
ZSCORE leaderboard "user1"
# 返回："100"
```

- **底层实现**：面试高频题！ZSet使用了两种编码方式：`ziplist`（元素少时，节省内存）和`skiplist`（跳跃表，元素多时，保证操作效率），提到跳跃表会非常加分。
- **应用场景**
- **排行榜**（经典场景）；
- **带权重的消息队列**（score作为优先级）。

### 5.3 Redis持久化机制

Redis持久化是指将内存中的数据以某种形式保存到磁盘，避免服务器重启或宕机导致数据丢失。Redis提供了两种主要机制：**RDB**和**AOF**。

**RDB（Redis Database）**：在指定时间间隔内，生成内存数据的一个**快照**（Snapshot），并将其保存为一个二进制的`.rdb`文件。这是一个全量备份。

> - **手动触发**
>   - `SAVE`命令：阻塞主进程，直到RDB文件创建完毕，期间服务器不处理任何请求；
>   - `BGSAVE`命令：**后台异步执行**，这是最常用的方式，Redis会`fork`出一个子进程来负责创建RDB文件，主进程继续处理命令。
> - **自动触发**
>   - 在`redis.conf`中配置，如 `save 900 1`（900秒内至少有1个key发生变化）。
>
> - **优点**：文件紧凑，体积小，适合灾难恢复和全量备份。恢复大数据集时速度比AOF快（直接加载到内存）。最大化Redis性能，因为持久化工作完全交给子进程；
> - **缺点**：无法做到**秒级**甚至更细粒度的数据丢失容忍（最后一次快照后的数据会丢失）。`fork`子进程时，如果数据量巨大，会导致主进程短暂阻塞，并且内存占用翻倍。
>
> **源码实现关键点（BGSAVE为例）**
>
> - **`fork`系统调用**：当主进程执行`BGSAVE`时，会调用`fork()`创建一个子进程，**写时复制（Copy-on-Write）**：这是关键，子进程与父进程共享同一片内存数据，当父进程（主进程）要修改某块数据时（如执行了一个`SET`命令），操作系统会将该内存页复制一份，子进程的指针依然指向旧的内存页。这样保证了子进程看到的数据是`fork`瞬间的快照，同时主进程可以继续服务。源码位置：`rdb.c`中的`rdbSaveBackground`函数；
>
> - **序列化过程**：子进程遍历Redis的**数据库字典**（`redisDb.dict`），将每个键值对按照特定的二进制格式序列化，这个过程是顺序I/O，性能很高，源码核心函数：`rdbSave`；
>
> - **临时文件与替换**：子进程会将数据写入一个**临时文件**（如`temp-<pid>.rdb`）。写入完成后，用这个临时文件**原子性地替换**旧的RDB文件。这避免了中途宕机导致备份文件损坏。

**AOF（Append Only File）**：将每一个**写命令**以Redis协议格式追加到一个日志文件的末尾，类似于MySQL的binlog，重启时，通过**重放（replay）** 日志中的所有命令来恢复数据。

> **工作流程**
>
> - **命令追加**：执行写命令后，将命令协议文本追加到`aof_buf`缓冲区；
>
> - **文件写入**：根据`appendfsync`策略，将缓冲区数据写入操作系统内核的页面缓存；
>   - `always`：每个命令都同步刷盘。数据最安全，性能最低；
>   - `everysec`：每秒刷一次盘，是默认策略，在性能和数据安全间取得平衡，最多丢失1秒数据；
>   - `no`：由操作系统决定何时刷盘，性能最好，但可能丢失大量数据。
>
> - **文件同步**：由操作系统将页面缓存的数据刷入磁盘。
>
> **AOF重写（Rewrite）**
>
> - **为什么需要**：AOF文件会随着运行而变大，恢复时间变长。且其中很多命令是冗余的（如对同一个key多次`SET`，只有最后一次有效）；
> - **如何实现**：创建一个新的AOF文件，这个文件包含了恢复当前数据集所需的**最小命令集合**。实现原理和RDB的`BGSAVE`类似。主进程`fork`一个子进程，子进程遍历数据库，将每个键值对用一条命令（如`SET`，`SADD`等）写入新的AOF文件；
> - **重写期间的增量数据**：在子进程重写期间，主进程的新写命令会同时写入原有的AOF缓冲区和AOF重写缓冲区，子进程完成重写后，向主进程发送信号，主进程将AOF重写缓冲区的数据追加到新的AOF文件中，然后原子地替换旧的AOF文件（<font color = red>这里为什么需要写入原有的AOF缓冲区：保证下一次的AOF重写不丢失数据</font>）。
>
> **优缺点**
>
> - **优点**：数据安全性高，配置得当最多丢失1秒数据，AOF文件易于理解和解析（纯文本格式）；
> - **缺点**：文件体积通常比RDB大，恢复速度慢于RDB（需要顺序执行所有命令），在QPS很高时，对磁盘压力较大。
>
> **源码实现关键点**
>
> - **命令传播**：在`call`函数（`server.c`）中，执行命令后，会调用`propagate`函数，最终将命令追加到`server.aof_buf`缓冲区；
>
> - **事件循环**：在Redis事件循环（`aeMain`）中，有一个定时任务（`serverCron`）和`beforeSleep`函数，它们会根据`appendfsync`策略调用`flushAppendOnlyFile`来执行写入和同步操作；
>
> - **AOF重写**：入口函数是`rewriteAppendOnlyFileBackground`（`aof.c`），内部同样使用`fork`和写时复制，处理重写缓冲区的逻辑在`backgroundRewriteDoneHandler`中。

**混合持久化（Redis 4.0+）**：结合了RDB和AOF的优点，在AOF重写时，子进程不再是直接写AOF格式命令，而是先像`BGSAVE`一样，将当前数据快照以RDB格式写入新的AOF文件的开头，然后，再将重写缓冲区中的增量命令以AOF格式追加到文件末尾。

> - **恢复过程**：重启时，先加载RDB部分的快照数据，再重放后面AOF格式的增量命令；
> - **优点**：既享受了RDB快速加载的优点，又享受了AOF不丢失太多数据的优点。这是目前推荐的持久化方式。

| 特性           | RDB                               | AOF                                      |
| :------------- | :-------------------------------- | :--------------------------------------- |
| **数据一致性** | 定时快照，可能丢失多数据          | 命令追加，最多丢失1秒数据（默认）        |
| **文件大小**   | 小，二进制压缩                    | 大，纯文本日志                           |
| **恢复速度**   | 快，直接加载                      | 慢，需重放命令                           |
| **对性能影响** | `fork`子进程时阻塞，COW有内存开销 | 主要在于文件同步策略（如`always`影响大） |
| **灾难恢复**   | 多个时间点备份，易于恢复          | 日志文件，恢复能力单一                   |

### 5.4 redis实现分布式锁

redis可以使用`setnx`实现简单的分布式锁，因为其操作是原子的，使用 SET 命令的 NX 和 PX 选项即可，其中一个线程执行了`setnx`命令，其它线程再执行`setnx`时会返回键已经存在的错误，无法进入到临界区。

```bash
# 原子性操作：设置锁并同时设置过期时间
SET lock_key unique_value NX PX 30000
```

大量 key 同时过期如何处理：使用随机数设置key的到期时间，使得redis删除key操作的时间分散一点。

### 5.5 使用Redis实现消息队列的几种方式

> **简单同步的消息队列**
>
> 使用 List 的 RPUSH 和 LPOP，加阻塞实现，当List满或为空时，生产者或消费者需要阻塞。
>
> ```bash
> # 1. 生产者命令
> # 从左侧插入消息（生产者）
> LPUSH queue:name "message_data"
> 
> # 从右侧插入消息
> RPUSH queue:name "message_data"
> 
> # 批量插入消息
> LPUSH queue:name "msg1" "msg2" "msg3"
> 
> # 2. 消费者命令
> # 阻塞式从右侧弹出消息（等待最多5秒）
> BRPOP queue:name 5
> 
> # 阻塞式从左侧弹出消息
> BLPOP queue:name 5
> 
> # 非阻塞弹出
> RPOP queue:name
> LPOP queue:name
> 
> # 3. 管理命令
> # 查看队列长度
> LLEN queue:name
> 
> # 查看队列元素（不消费）
> LRANGE queue:name 0 -1
> 
> # 修剪队列，只保留最近100个元素
> LTRIM queue:name 0 99
> ```
>
> **优点**
>
> - 实现简单，性能高；
> - 支持阻塞获取，减少空轮询；
> - 消息持久化。
>
> **缺点**
>
> - 无消息确认机制（消息取出即删除）；
> - 不支持消息重试；
> - 无优先级支持。
>
> **发布订阅模式**
>
> 使用redis的发布订阅模式，该方式实现的消息发布是无状态的，无法保证可达，是不可靠的消息队列，该方式可以实现异步，多消费者。
>
> ```bash
> # 1. 发布者命令
> # 向频道发布消息
> PUBLISH news.channel "message_content"
> 
> # 向多个频道发布
> MULTI
> PUBLISH channel1 "msg1"
> PUBLISH channel2 "msg2"
> EXEC
> 
> # 2. 订阅者命令
> # 订阅一个或多个频道
> SUBSCRIBE news.channel notifications
> 
> # 使用模式匹配订阅
> PSUBSCRIBE news.*
> 
> # 取消订阅
> UNSUBSCRIBE news.channel
> PUNSUBSCRIBE news.*
> 
> # 3. 管理命令
> # 查看频道订阅者数量
> PUBSUB NUMSUB news.channel
> 
> # 查看模式订阅数量
> PUBSUB NUMPAT
> 
> # 查看所有活跃频道
> PUBSUB CHANNELS
> ```
>
> **优点**
>
> - 真正的实时消息推送；
> - 支持一对多广播；
> - 模式匹配订阅。
>
> **缺点**
>
> - **消息不持久化**（订阅者离线期间的消息会丢失）；
> - 无消息堆积能力；
> - 无消费者状态管理。
>
> **基于 Stream 的可靠消息队列**
>
> Redis 5.0引入的Stream数据结构，提供完整的消息队列功能，支持消费者组、消息确认、消息重试等高级特性。
>
> **消费者组工作流程**
>
> 1. **创建组**：`XGROUP CREATE`创建消费者组；
> 2. **生产消息**：`XADD`向Stream添加消息；
> 3. **消费消息**：消费者使用`XREADGROUP`读取消息；
> 4. **消息确认**：处理完成后使用`XACK`确认；
> 5. **消息重试**：超时未确认的消息可被其他消费者认领。
>
> **消息ID格式**
>
> Stream消息ID格式：`<毫秒时间戳>-<序列号>`
>
> - `1526919030474-0`：精确到毫秒的时间戳 + 序列号；
> - 支持自定义ID，但必须大于最后一条消息的ID。
>
> **优点**
>
> - 完整的消息队列功能（ACK、重试、持久化）；
> - 支持消费者组和负载均衡；
> - 消息可追溯和重放；
> - 高性能和可靠性。
>
> **缺点**
>
> - 需要Redis 5.0+版本；
> - 命令相对复杂；
> - 内存占用相对较高。

### 5.6 什么是Redis的过期策略，内存淘汰机制都有哪些，手写LRU算法？

> 策略：Redis采用惰性删除和定期删除结合的方式来处理过期键。
>
> - 惰性删除：只在访问键时检查是否过期，如果过期则立即删除；
>
> - 定期删除：Redis定期随机抽取一部分过期键进行检查和删除（随机抽取，所以过期的键不一定会删除）。
>
> 内存淘汰机制：当内存达到`maxmemory`限制时，Redis根据配置的淘汰策略删除键。
>
> - 不淘汰策略：返回错误；
> - 所有键使用 LRU 淘汰策略；
> - 过期键使用 LRU 淘汰策略；
>
> - TTL：淘汰生存时间最少的键值。
>
> LRU算法的实现：记住需要使用的核心数据结构哈希表和双向链表即可。

### 5.7 Redis的并发竞争问题该如何解决？

使用分布式锁 + 时间戳的形式，时间戳也就是在数据库中存储的value，加上update_time字段。

### 5.8 Redis缓存雪崩 + 击穿 + 数据库缓存一致性问题如何解决？

> **缓存雪崩**：大量缓存键在同一时间**大规模失效**，导致所有请求直接打到数据库，造成数据库瞬时压力过大而宕机。（<font color = red>针对大量key过期，导致客户端的许多访问落到数据库上</font>）
>
> **解决方法**
>
> - 使用随机值让过期时间随机化（先记住这一个吧）；
> - 多级缓存架构；
> - 构建缓存集群。



> **缓存击穿**：某个**热点键过期**的瞬间，大量并发请求同时访问这个键，导致所有请求直接打到数据库。（<font color = red>针对某一个key过期，大量客户端访问该key落到数据库上</font>）
>
> **解决方法**
>
> - 使用redis的分布式锁，当某个键值不存在的时候，保证只有一个线程可以`setnx`，其它线程阻塞在`setnx`中，只能等待下一次的读缓存操作；



> **缓存穿透**：查询数据库中根本不存在的数据，由于数据库不存在，redis中也不存在，所以导致每次请求都直接访问数据库。（<font color = red>访问数据库不存在的key</font>）
>
> **解决方法**
>
> - 使用布隆过滤器过滤非法的键值查询；
> - 当在数据库中查询不存在的数据后，在redis中缓存空值，并且设置较短的过期时间，这样保证某一个时间段内只有一个线程访问数据库。



> **数据一致性**：当数据发生变更时（增删改），我们需要同时更新数据库和缓存。这两个操作不是原子性的，以何种顺序、在何时机进行更新，才能在高并发环境下，最大限度地避免读到脏数据（缓存和数据库数据不一致）？
>
> **解决方案**
>
> **核心思想**：承认“完美强一致性”在高并发下代价高昂，通常追求最终一致性，并根据业务场景选择对业务影响最小的更新策略。
>
> **核心矛盾**：更新数据库和更新缓存是两个独立操作，无法原子性完成。各种策略的优劣主要体现在并发读写时出现不一致窗口期的长短和概率。
>
> **常见策略分析**
>
> 1. **先更新数据库，再删除缓存**（<font color = red>这个最基础，一定要记住</font>）
>
>    - **原理**：这是最常用的策略，也称为`Cache-Aside`模式中的更新逻辑。先更新数据库，然后使缓存失效（删除）。下次读请求时，会因缓存缺失而从数据库加载最新数据；
>    - **不一致场景**：在“更新数据库后，删除缓存前”这个极短的时间窗口内，可能有读请求将旧数据读入缓存。但因为这个窗口非常短，不一致的概率相对较低；
>    - **优点**：避免了“先删缓存”策略下，在更新数据库期间大量请求击穿到数据库的问题。
>
> 2. **先删除缓存，再更新数据库**
>
>    - **原理**：先让缓存失效，再更新数据库；
>    - **不一致场景**：在“删除缓存后，更新数据库前”，一个读请求可能将旧数据读入缓存，随后数据库更新完成，导致缓存中一直是脏数据直到过期。这个不一致窗口期可能很长。
>
> 3. **延迟双删**
>
>    - **原理**：为了优化策略2的问题，采用“先删缓存 -> 更新数据库 -> 休眠一段时间（如几百毫秒，主要考虑主从同步和并发读请求的完成时间）-> 再次删除缓存”。第二次删除的目的是清除在更新数据库期间可能被写入缓存的旧数据；
>    - **要点**：休眠时间需要根据业务压测确定，且第二次删除失败可能仍需重试机制。
>
> 4. **高级方案**：通过数据库Binlog异步淘汰缓存（<font color = red>拓展优先记住这个</font>）
>
>    - **原理**：这是保证最终一致性的优雅方案。业务代码只需更新数据库。然后，由一个独立的订阅程序（如Canal、Debezium）来订阅数据库的Binlog（日志文件）。当订阅程序解析到数据变更的日志后，向消息队列发送一个删除缓存的消息。另一个缓存更新服务消费该消息，执行缓存删除操作;
>
>    - **优点**：将缓存更新与业务逻辑解耦，保证了操作的顺序性，且即使缓存删除失败，也可以通过重试机制保证最终一致。这是大型互联网公司的首选方案。

### 5.9 哈希扩容

> **Redis中哈希扩展与收缩的条件**
>
> 当以下条件满足任意一个时，程序就会对哈希表进行扩展操作
>
> - 服务器目前没有执行bgsave或bgrewriteaof命令，并且哈希表的负载因子>=1；
> - 服务器目前正在执行bgsave或bgrewriteaof命令，并且哈希表的负载因子>=5。
>
> 负载因子的计算：load_factor=ht[0].used/ht[0].size 。
>
> 当负载因子的值小于0.1时，程序就会对哈希表进行收缩操作。
>
> **Redis的渐进式rehash**
>
> **原因**：整个rehash过程并不是一步完成的，而是分多次、渐进式的完成。如果哈希表中保存着数量巨大的键值对时，若一次进行rehash，很有可能会导致服务器宕机。
>
> **步骤**
>
> - 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表；
> - 维持索引计数器变量rehashidx，并将它的值设置为0，表示rehash开始；
> - 每次对字典执行增删改查时，将ht[0]的rehashidx索引上的所有键值对rehash到ht[1]，将rehashidx值+1；
> - 当ht[0]的所有键值对都被rehash到ht[1]中，程序将rehashidx的值设置为-1，表示rehash操作完成。
>
> **优势**：渐进式rehash的好处在于它采取分为而治的方式，将rehash键值对的计算均摊到每个字典增删改查操作，避免了集中式rehash的庞大计算量。

### 5.10 分布式一致性算法

